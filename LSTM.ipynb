{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jesperiksson/struc-mon/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l11DflmDq5f",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjfjyLk_D2hs",
        "colab_type": "code",
        "outputId": "496e28b8-0a80-428a-bea6-8a34e890f59c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSt6vS28Dpev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import h5py\n",
        "import scipy as sp\n",
        "import scipy.signal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prMXVEXDDpe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    use = 'LSTM'\n",
        "    name = 'onlineCudnnData'\n",
        "    #####################\n",
        "\n",
        "    architecture = {\n",
        "        'name' :use + name,\n",
        "        'active_sensors' : ['90'],\n",
        "        'predict' : 'accelerations', # accelerations or damage\n",
        "        'path' : '/content/drive/My Drive/KTH/Examensarbete/struc-mon (kopia)/our_measurements3/e90',\n",
        "        'random_mode' : 'test' # test or debug\n",
        "        }\n",
        "    sensor_dict = {}\n",
        "    for i in range(len(architecture['active_sensors'])):\n",
        "        sensor_dict.update({\n",
        "            architecture['active_sensors'][i] : i\n",
        "            })\n",
        "    architecture.update({\n",
        "        'sensors' : sensor_dict\n",
        "        })\n",
        "    plotting = {\n",
        "        'prediction_performance' : True,\n",
        "        'prediction_confusion_matrix' : True,\n",
        "        'prediction_roc' : False, # To be implemented\n",
        "        'forecast_performance' : True,\n",
        "        'forecast_confusion_matrix' : True\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRVke1uvDpe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "architecture.update({\n",
        "            'model' : 'two_layer',\n",
        "            # Net configuaration\n",
        "            'n_units' : {'first' : 500, 'second' : 250},\n",
        "            'bias' : True,\n",
        "            'n_pattern_steps' : 1000, # Kan ändras\n",
        "            'n_target_steps' : 100,\n",
        "            'pattern_delta' : 40,\n",
        "            # Sensor parameters\n",
        "            'pattern_sensors' : ['90'],\n",
        "            'target_sensor' : '90',\n",
        "            'target_sensors' : ['90'],\n",
        "            # Training parameters\n",
        "            'batch_size' : 10,\n",
        "            'data_split' : {'train':60, 'validation':20, 'test':20}, # sorting of data \n",
        "            'mode' : '1',\n",
        "            'delta' : 1, # Kan ändras\n",
        "            'Dense_activation' : 'tanh',\n",
        "            'early_stopping' : True,\n",
        "            'epochs' : 200,\n",
        "            'learning_rate' : 0.001, # 0.001 by default\n",
        "            'min_delta' : 0.01,\n",
        "            'LSTM_activation' : 'tanh',\n",
        "            'preprocess_type' : 'data',\n",
        "            'patience' : 50,\n",
        "            # Data interval\n",
        "            'from' : 0,\n",
        "            'to' : -1,\n",
        "            # Model saving\n",
        "            'save_periodically' : True,\n",
        "            'save_interval' : 1, # Number of series to train on before saving\n",
        "            # Classification\n",
        "            'limit' : 0.9\n",
        "        })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUNPg6mgDpe7",
        "colab_type": "code",
        "outputId": "d00d890d-5c74-41c6-b5f3-69c9d0900643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "architecture"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dense_activation': 'tanh',\n",
              " 'LSTM_activation': 'tanh',\n",
              " 'active_sensors': ['90'],\n",
              " 'batch_size': 10,\n",
              " 'bias': True,\n",
              " 'data_split': {'test': 20, 'train': 60, 'validation': 20},\n",
              " 'delta': 1,\n",
              " 'early_stopping': True,\n",
              " 'epochs': 200,\n",
              " 'from': 0,\n",
              " 'learning_rate': 0.001,\n",
              " 'limit': 0.9,\n",
              " 'min_delta': 0.01,\n",
              " 'mode': '1',\n",
              " 'model': 'two_layer',\n",
              " 'n_pattern_steps': 1000,\n",
              " 'n_target_steps': 100,\n",
              " 'n_units': {'first': 500, 'second': 250},\n",
              " 'name': 'LSTMonlineCudnnData',\n",
              " 'path': '/content/drive/My Drive/KTH/Examensarbete/struc-mon (kopia)/our_measurements3/e90',\n",
              " 'patience': 50,\n",
              " 'pattern_delta': 40,\n",
              " 'pattern_sensors': ['90'],\n",
              " 'predict': 'accelerations',\n",
              " 'preprocess_type': 'data',\n",
              " 'random_mode': 'test',\n",
              " 'save_interval': 1,\n",
              " 'save_periodically': True,\n",
              " 'sensors': {'90': 0},\n",
              " 'target_sensor': '90',\n",
              " 'target_sensors': ['90'],\n",
              " 'to': -1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvJYexb7DpfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_to_NN(\n",
        "        data_split, \n",
        "        path, \n",
        "        healthy_percentage, \n",
        "        arch):\n",
        "    \n",
        "    types = arch['preprocess_type']\n",
        "    paths = {}\n",
        "\n",
        "    for i in range(len(arch['active_sensors'])):\n",
        "        paths.update(\n",
        "            {arch['active_sensors'][i] : path+'s'+arch['active_sensors'][i]+'/'})\n",
        "    if arch['random_mode'] == 'debug':\n",
        "        seed = 1\n",
        "    elif arch['random_mode'] == 'test':\n",
        "        seed = random.randint(0,10000)\n",
        "    file_list = os.listdir(paths[arch['active_sensors'][0]])\n",
        "    file_list.sort()\n",
        "    random.Random(seed).shuffle(file_list)\n",
        "\n",
        "    speeds = np.empty([len(file_list)])\n",
        "    for i in range(len(file_list)):\n",
        "        if len(file_list[i]) == 9:\n",
        "            speeds[i] = int(file_list[i][0:5])\n",
        "        elif len(file_list[i]) == 10:\n",
        "            speeds[i] = int(file_list[i][0:6])\n",
        "        else: \n",
        "            print('error')\n",
        "    normalized_speeds = (speeds-min(speeds))/(max(speeds)-min(speeds))\n",
        "\n",
        "    n_files = len(file_list)\n",
        "    data_stack = {}\n",
        "    preprocess_stack = {}\n",
        "    peaks_stack = {}\n",
        "    frequency_stack = {}\n",
        "    extrema_stack = {}\n",
        "    start = arch['from']\n",
        "    to = arch['to']\n",
        "    diff = to-start\n",
        "    for i in range(n_files):\n",
        "        data = [None]*len(paths)\n",
        "        for j in range(len(paths)):\n",
        "            mat = h5py.File(paths[arch['active_sensors'][j]] + file_list[i], 'r')\n",
        "            data[j] = mat.get('acc')[1,start:to]\n",
        "\n",
        "        if i/n_files < (data_split['train']/100):\n",
        "            category = 'train'\n",
        "        elif i/n_files > (data_split['validation']/100) and i/n_files < ((data_split['train']+data_split['validation'])/100):\n",
        "            category = 'validation'\n",
        "        else:\n",
        "            category = 'test'\n",
        "        if 'data' in types:\n",
        "            data_stack.update({\n",
        "                'batch'+str(i) : DataBatch(data,\n",
        "                                 i,\n",
        "                                 speeds[i]/1000,\n",
        "                                 normalized_speeds[i],\n",
        "                                 category,\n",
        "                                 healthy_percentage)\n",
        "                                })\n",
        "        if 'frequency' in types:\n",
        "            frequency_stack.update({\n",
        "                'batch'+str(i) : frequencySpectrum(data,\n",
        "                                 i,\n",
        "                                 speeds[i]/1000,\n",
        "                                 normalized_speeds[i],\n",
        "                                 category,\n",
        "                                 healthy_percentage)\n",
        "                                })\n",
        "        if 'peaks' in types:\n",
        "            peaks_stack.update({\n",
        "                'batch'+str(i) : peaks(data,\n",
        "                                 i,\n",
        "                                 speeds[i]/1000,\n",
        "                                 normalized_speeds[i],\n",
        "                                 category,\n",
        "                                 healthy_percentage)\n",
        "                                })\n",
        "        if 'extrema' in types:\n",
        "            extrema_stack.update({\n",
        "            'batch'+str(i) : extrema(data,\n",
        "                             i,\n",
        "                             speeds[i]/1000,\n",
        "                             normalized_speeds[i],\n",
        "                             category,\n",
        "                             healthy_percentage)\n",
        "                            })\n",
        "\n",
        "    preprocess_stack.update({\n",
        "        'data' : data_stack,\n",
        "        'frequency' : frequency_stack,\n",
        "        'peaks' : peaks_stack,\n",
        "        'extrema' : extrema_stack\n",
        "        })    \n",
        "\n",
        "    return preprocess_stack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNCcgbskDpfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataBatch():\n",
        "    def __init__(self, data, batch_num, speed, normalized_speed, category, damage_state):\n",
        "        self.data = np.array(data)\n",
        "        self.unnormalized_data = np.array(data)\n",
        "        for i in range(np.shape(data)[0]):\n",
        "            self.data[i,:] = self.data[i,:]/max(abs(self.data[i,:]))\n",
        "        #self.data = preprocessing.normalize(self.data)\n",
        "        self.sensors = np.shape(data)[0]\n",
        "        self.batch_num = batch_num\n",
        "        self.category = category\n",
        "        self.n_steps = np.shape(self.data)[1]\n",
        "        self.speed = {'km/h' : speed, 'm/s' : (speed*3.6/10)}\n",
        "        self.normalized_speed = normalized_speed\n",
        "        self.damage_state = damage_state\n",
        "        self.normalized_damage_state = damage_state/100\n",
        "        self.timestep = 0.001\n",
        "        self.timesteps = np.arange(0, self.n_steps, 1)\n",
        "        self.steps = [None]*self.sensors\n",
        "        self.indices = [None]*self.sensors\n",
        "        self.delta = [None]*self.sensors\n",
        "        for i in range(self.sensors):\n",
        "            self.steps[i] = self.n_steps\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXje9RQoDpfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_split_mode2(a):\n",
        "    series_stack = {}\n",
        "    damage_dir_list = os.listdir(a['path'])\n",
        "    for j in range(len(damage_dir_list)):\n",
        "        series_stack.update({\n",
        "            damage_dir_list[j] : fit_to_NN(\n",
        "                a['data_split'],\n",
        "                a['path']+'/'+damage_dir_list[j]+'/', \n",
        "                int(damage_dir_list[j][:-1]),\n",
        "                a)\n",
        "            })\n",
        "    return series_stack\n",
        "\n",
        "def data_split_mode1(a):\n",
        "    eval_series_stack = {}\n",
        "    damage_dir_list = os.listdir(a['path'])\n",
        "    for j in range(len(damage_dir_list)):\n",
        "        if damage_dir_list[j] == '100%':\n",
        "            eval_series_stack.update({\n",
        "                damage_dir_list[j] : fit_to_NN(\n",
        "                    a['data_split'],\n",
        "                    a['path']+'/'+damage_dir_list[j]+'/',\n",
        "                    int(damage_dir_list[j][:-1]),\n",
        "                    a)\n",
        "                })\n",
        "        else:\n",
        "            eval_series_stack.update({\n",
        "                damage_dir_list[j] : fit_to_NN(\n",
        "                    {'train' : 0, 'validation' : 0, 'test' : 100},\n",
        "                    a['path']+'/'+damage_dir_list[j]+'/',\n",
        "                    int(damage_dir_list[j][:-1]),\n",
        "                    a)\n",
        "                })\n",
        "    return eval_series_stack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgR6Z9eYDpfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class peaks(DataBatch):\n",
        "    def __init__(self, data, batch_num, speed, normalized_speed, category, damage_state):  \n",
        "        super().__init__(data, batch_num, speed, normalized_speed, category, damage_state)\n",
        "        self.peaks = [None]*self.sensors\n",
        "        for i in range(self.sensors):\n",
        "            self.indices[i], properties = sp.signal.find_peaks(\n",
        "                self.data[i], \n",
        "                height = None, \n",
        "                threshold = None,\n",
        "                distance = 2,\n",
        "                prominence = None,\n",
        "                width = None)\n",
        "            self.peaks[i] = self.data[i][self.indices[i]]\n",
        "            \n",
        "            delta = np.diff(self.indices[i])\n",
        "            self.delta[i] = delta/max(delta)\n",
        "        self.n_steps = np.shape(self.peaks[0])[0] # overwrite data\n",
        "        self.timesteps = self.indices[0]\n",
        "        self.data = self.peaks "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5DijcxwrDpfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    if architecture['mode'] == '1':\n",
        "        series_stack = data_split_mode1(architecture)\n",
        "        '''\n",
        "        This is the normal case where all available data is divided into train/ test/ validation\n",
        "        '''\n",
        "\n",
        "    elif architecture['mode'] == '2':\n",
        "        series_stack = data_split_mode2(architecture)\n",
        "        '''\n",
        "        This is special case where only healthy data is used for training and \n",
        "        all damaged data is used for testing.\n",
        "        '''\n",
        "    #series_stack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubCFOmQmDpfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.models import Sequential, Model, model_from_json\n",
        "from tensorflow.python.keras.layers import Input, Dense, CuDNNLSTM, concatenate, Activation, Reshape, Bidirectional\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.python.keras import metrics, regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k908Zt4XDpfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet():\n",
        "    def __init__(self,\n",
        "                 arch,\n",
        "                 name,\n",
        "                 existing_model = False):\n",
        "\n",
        "        self.arch = arch\n",
        "        self.name = name\n",
        "        self.target_sensor = self.arch['sensors'][self.arch['target_sensor']]\n",
        "        self.pattern_sensors = self.arch['sensors'][self.arch['pattern_sensors'][0]]\n",
        "        self.sensor_to_predict = arch['sensors'][arch['target_sensor']]\n",
        "        if arch['early_stopping'] == True:\n",
        "            self.early_stopping = [keras.callbacks.EarlyStopping(\n",
        "                monitor='loss',\n",
        "                min_delta=arch['min_delta'], \n",
        "                patience=arch['patience'],\n",
        "                verbose=1,\n",
        "                mode='auto',\n",
        "                restore_best_weights=True)]\n",
        "\n",
        "        else:\n",
        "            self.early_stopping = None\n",
        "        self.existing_model = existing_model\n",
        "        self.n_sensors = len(arch['sensors'])    \n",
        "        model_dict = {\n",
        "            'single_layer' : set_up_model6(arch),\n",
        "            'two_layer' : set_up_model7(arch)\n",
        "            }     \n",
        "        if self.existing_model == False:\n",
        "            model = model_dict[arch['model']]\n",
        "\n",
        "        elif self.existing_model == True:\n",
        "            model_path = '/content/drive/My Drive/KTH/Examensarbete/struc-mon (kopia)/models/'+self.arch['name']+'.json'\n",
        "            weights_path = '/content/drive/My Drive/KTH/Examensarbete/struc-mon (kopia)/models/'+self.arch['name']+'.h5'\n",
        "            json_file = open(model_path)\n",
        "            loaded_model_json = json_file.read()\n",
        "            json_file.close()\n",
        "            loaded_model = model_from_json(loaded_model_json)\n",
        "            loaded_model.load_weights(weights_path)\n",
        "            model = loaded_model\n",
        "            print('\\n Loaded model: ', name)\n",
        "        else:\n",
        "            raise Error\n",
        "        optimizer = keras.optimizers.Adam(\n",
        "            learning_rate = arch['learning_rate'],\n",
        "            beta_1=0.9,\n",
        "            beta_2=0.999,\n",
        "            epsilon=1e-07,\n",
        "            amsgrad=False)\n",
        "        model.compile(\n",
        "            optimizer=optimizer, \n",
        "            loss=rmse, \n",
        "            metrics=[rmse])\n",
        "        plot_model(model, to_file=name+'.png')\n",
        "        model.summary()\n",
        "        self.model = model\n",
        "        self.score = None\n",
        "        self.loss = [None]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r1eOLajDpff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def train(self, series_stacks):\n",
        "        tic = time.time()\n",
        "        self.history = [None]\n",
        "        self.loss = [None]\n",
        "        self.val_loss = [None]\n",
        "        keys = list(series_stacks.keys())\n",
        "        for h in range(len(keys)):\n",
        "            series_stack = series_stacks[keys[h]]\n",
        "            print('\\nTraining on ', keys[h],'% healthy data.\\n')\n",
        "            print('\\n Number of series being used for training:', len(series_stack[self.arch['preprocess_type']]), '\\n')\n",
        "            for i in range(len(series_stack[self.arch['preprocess_type']])):\n",
        "                series = series_stack[self.arch['preprocess_type']]['batch'+str(i)]\n",
        "                if series.category == 'train' or series.category == 'validation':\n",
        "                    print('\\nFitting series: ', i, ' out of:', len(series_stack[self.arch['preprocess_type']]))\n",
        "                    X, Y = generator(self, series)\n",
        "                    patterns = {\n",
        "                        'speed_input' : np.array([series.normalized_speed]),\n",
        "                        'damage_input' : series.normalized_damage_state}\n",
        "                    for j in range(len(self.arch['active_sensors'])):\n",
        "                        patterns.update({\n",
        "                            'accel_input_'+str(self.arch['pattern_sensors'][j]) : X # Ange vilken\n",
        "                        })\n",
        "                    targets = {\n",
        "                        'accel_output_'+str(self.arch['pattern_sensors'][j]) : Y,\n",
        "                        'damage_state_output' : series.normalized_damage_state\n",
        "                        }           \n",
        "                    history = self.model.fit(\n",
        "                        x = X,#patterns,\n",
        "                        y = Y,#targets, \n",
        "                        batch_size = self.arch['batch_size'],\n",
        "                        epochs=self.arch['epochs'], \n",
        "                        verbose=1,\n",
        "                        callbacks=self.early_stopping, #self.learning_rate_scheduler],\n",
        "                        validation_split = self.arch['data_split']['validation']/100,\n",
        "                        shuffle = True)\n",
        "                    self.history.append(history)\n",
        "                    self.loss.extend(history.history['loss'])\n",
        "                    self.val_loss.extend(history.history['val_loss'])  \n",
        "                    if self.arch['save_periodically'] == True and i % self.arch['save_interval'] == 0:\n",
        "                        save_model(self.model,self.name)  \n",
        "        self.model.summary()\n",
        "        self.toc = np.round(time.time()-tic,1)\n",
        "        print('Elapsed time: ', self.toc)\n",
        "        return\n",
        "    NeuralNet.train = train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me8D5YlcDpfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmse(true, prediction):\n",
        "    return backend.sqrt(backend.mean(backend.square(prediction - true), axis=-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bri10edqDpfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_steps(self, series):\n",
        "    steps = int(\n",
        "        np.floor(\n",
        "            (series.n_steps-(self.arch['n_pattern_steps']+self.arch['n_target_steps']))/self.arch['pattern_delta']\n",
        "        )\n",
        "    )\n",
        "    return steps  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THSdY7y8Dpfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def evaluation(self, series_stack):\n",
        "        scores = []\n",
        "        speeds = []\n",
        "        damage_states = []\n",
        "        for i in range(len(series_stack[self.arch['preprocess_type']])):\n",
        "            series = series_stack[self.arch['preprocess_type']]['batch'+str(i)]\n",
        "            if series.category == 'test':\n",
        "                X, Y = generator(self, series)\n",
        "                score = self.model.evaluate(\n",
        "                    x = X,\n",
        "                    y = Y,\n",
        "                    batch_size = self.arch['batch_size'],\n",
        "                    verbose = 1,\n",
        "                    return_dict = True)\n",
        "                speeds.extend([series.speed['km/h']])\n",
        "                scores.extend([score['rmse']])\n",
        "                damage_states.extend([series.damage_state])\n",
        "            \n",
        "        results = {\n",
        "            'scores' : scores[:],\n",
        "            'speeds' : speeds[:],\n",
        "            'steps' : len(speeds[:]),\n",
        "            'damage_state' : damage_states[:]\n",
        "        }\n",
        "        return results\n",
        "    NeuralNet.evaluation = evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1HbOvLJDpft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(self, batch):\n",
        "    '''\n",
        "    Generator for when to use Peak accelerations and locations\n",
        "    Each series of data is so big it has to be broken down\n",
        "    '''\n",
        "    steps = get_steps(self, batch)\n",
        "    #print(steps)\n",
        "    X = np.empty([steps,self.arch['n_pattern_steps'], len(self.arch['pattern_sensors'])])\n",
        "    Y = np.empty([steps,self.arch['n_target_steps']])\n",
        "    for j in range(len(self.arch['pattern_sensors'])):     \n",
        "        for k in range(steps):    \n",
        "            pattern_start = k*self.arch['pattern_delta']\n",
        "            pattern_finish = k*self.arch['pattern_delta']+self.arch['delta']*self.arch['n_pattern_steps']\n",
        "            target_start = k*self.arch['pattern_delta']+self.arch['delta']*self.arch['n_pattern_steps'] # +1?\n",
        "            target_finish = k*self.arch['pattern_delta']+self.arch['delta']*(self.arch['n_pattern_steps']+self.arch['n_target_steps'])\n",
        "            X[k,:,j] = batch.data[j][pattern_start:pattern_finish]\n",
        "            Y[k,:] = batch.data[j][target_start:target_finish]\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNoRA3h3Dpfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model,name):\n",
        "    model_json = model.to_json()\n",
        "    with open('/content/drive/My Drive/KTH/Examensarbete/struc-mon (kopia)/models/'+name+'.json', 'w') as json_file:\n",
        "        json_file.write(model_json)\n",
        "        # serialize weights to HDF5\n",
        "    model.save_weights('/content/drive/My Drive/KTH/Examensarbete/struc-mon (kopia)/models/'+name+'.h5')\n",
        "    print('Saved model:', name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn6t0iddFJlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(self, name):\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(self.loss)), self.loss, 'bo', label='Training loss', linewidth=0.3)\n",
        "    plt.plot(range(len(self.val_loss)), self.val_loss, 'ro', label='Validation loss', linewidth=0.3)\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss - RMSE')\n",
        "    plt.legend()\n",
        "    plt.savefig(fname = name+'_loss_plot.png')\n",
        "    plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QZSYNeDDpf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_up_model6(arch): # Vanilla \n",
        "\n",
        "    accel_input = Input(\n",
        "        shape=(\n",
        "            arch['n_pattern_steps'], \n",
        "            1),\n",
        "        name = 'accel_input_90')\n",
        "\n",
        "    hidden_lstm_1 = CuDNNLSTM(\n",
        "        arch['n_units']['first'],\n",
        "        batch_input_shape = (\n",
        "            arch['batch_size'],\n",
        "            arch['n_pattern_steps'],\n",
        "            1),\n",
        "        #activation = 'tanh',\n",
        "        #recurrent_activation = 'sigmoid',\n",
        "        #use_bias = True,\n",
        "        #dropout = 0.1,\n",
        "        #recurrent_dropout = 0,\n",
        "        #unroll = False,\n",
        "        return_sequences = True,\n",
        "        stateful = False)(accel_input)\n",
        "\n",
        "    output = Dense(\n",
        "        arch['n_target_steps'], \n",
        "        activation='tanh', \n",
        "        name='peak_output_90')(hidden_lstm_1)\n",
        "\n",
        "    model = Model(inputs = accel_input, outputs = output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHoJqUzVDpf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_up_model7(arch):\n",
        "\n",
        "    accel_input = Input(\n",
        "        shape=(\n",
        "            arch['n_pattern_steps'], \n",
        "            1),\n",
        "        name = 'accel_input_90')\n",
        "\n",
        "    hidden_lstm_1 = CuDNNLSTM(\n",
        "        arch['n_units']['first'],\n",
        "        batch_input_shape = (\n",
        "            arch['batch_size'],\n",
        "            arch['n_pattern_steps'],\n",
        "            1),\n",
        "        #activation = 'tanh',\n",
        "        #recurrent_activation = 'sigmoid',\n",
        "        #use_bias = True,\n",
        "        #dropout = 0.1,\n",
        "        #recurrent_dropout = 0,\n",
        "        #unroll = False,\n",
        "        return_sequences = True,\n",
        "        stateful = False)(accel_input)\n",
        "\n",
        "    hidden_lstm_2 = CuDNNLSTM(\n",
        "        arch['n_units']['second'],\n",
        "        batch_input_shape = (\n",
        "            arch['batch_size'],\n",
        "            arch['n_pattern_steps'],\n",
        "            1),\n",
        "        #activation = 'tanh',\n",
        "        #recurrent_activation = 'sigmoid',\n",
        "        #use_bias = True,\n",
        "        #dropout = 0.1,\n",
        "        #recurrent_dropout = 0,\n",
        "        #unroll = False,\n",
        "        stateful = False)(hidden_lstm_1)\n",
        "\n",
        "    output = Dense(\n",
        "        arch['n_target_steps'], \n",
        "        activation='tanh', \n",
        "        name='peak_output_90')(hidden_lstm_2)\n",
        "\n",
        "    model = Model(inputs = accel_input, outputs = output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la1kWLB0Dpf3",
        "colab_type": "code",
        "outputId": "43fee162-d41f-4171-f214-6fd7cfc40a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    machine_stack = {}\n",
        "    \n",
        "    for i in range(len(architecture['target_sensors'])):\n",
        "        architecture['target_sensor'] = architecture['target_sensors'][i]\n",
        "        name = architecture['name']\n",
        "        try:\n",
        "            f = open('/content/drive/My Drive/KTH/Examensarbete/struc-mon (kopia)/models/'+name+'.json')\n",
        "            machine_stack.update({\n",
        "                name : NeuralNet(architecture,\n",
        "                     name,\n",
        "                     existing_model = True)\n",
        "            })\n",
        "        except IOError:    \n",
        "            machine_stack.update({\n",
        "                name : NeuralNet(architecture,\n",
        "                     name,\n",
        "                     existing_model = False)\n",
        "            })\n",
        "        NeuralNet.train(machine_stack[name], series_stack)  \n",
        "        save_model(machine_stack[name].model, name)\n",
        "        plot_loss(machine_stack[name], name)  \n",
        "        \n",
        "        score_stack = {}\n",
        "        keys = list(series_stack)\n",
        "        \n",
        "        for j in range(len(keys)):\n",
        "            score_stack.update({\n",
        "                keys[j] : NeuralNet.evaluation(machine_stack[name], series_stack[keys[j]])\n",
        "            })"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Loaded model:  LSTMonlineCudnnData\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "accel_input_90 (InputLayer)  [(None, 1000, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 1000, 500)         1006000   \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)     (None, 250)               752000    \n",
            "_________________________________________________________________\n",
            "peak_output_90 (Dense)       (None, 100)               25100     \n",
            "=================================================================\n",
            "Total params: 1,783,100\n",
            "Trainable params: 1,783,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Training on  57% % healthy data.\n",
            "\n",
            "\n",
            " Number of series being used for training: 6 \n",
            "\n",
            "\n",
            "Training on  67% % healthy data.\n",
            "\n",
            "\n",
            " Number of series being used for training: 6 \n",
            "\n",
            "\n",
            "Training on  90% % healthy data.\n",
            "\n",
            "\n",
            " Number of series being used for training: 6 \n",
            "\n",
            "\n",
            "Training on  93% % healthy data.\n",
            "\n",
            "\n",
            " Number of series being used for training: 4 \n",
            "\n",
            "\n",
            "Training on  71% % healthy data.\n",
            "\n",
            "\n",
            " Number of series being used for training: 6 \n",
            "\n",
            "\n",
            "Training on  95% % healthy data.\n",
            "\n",
            "\n",
            " Number of series being used for training: 6 \n",
            "\n",
            "\n",
            "Training on  86% % healthy data.\n",
            "\n",
            "\n",
            " Number of series being used for training: 6 \n",
            "\n",
            "\n",
            "Training on  100% % healthy data.\n",
            "\n",
            "\n",
            " Number of series being used for training: 32 \n",
            "\n",
            "\n",
            "Fitting series:  0  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 0.0393 - rmse: 0.0393 - val_loss: 0.1131 - val_rmse: 0.1131\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0304 - rmse: 0.0304 - val_loss: 0.1101 - val_rmse: 0.1101\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0264 - rmse: 0.0264 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0224 - rmse: 0.0224 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0207 - rmse: 0.0207 - val_loss: 0.1103 - val_rmse: 0.1103\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0192 - rmse: 0.0192 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0175 - rmse: 0.0175 - val_loss: 0.1108 - val_rmse: 0.1108\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0196 - rmse: 0.0196 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0176 - rmse: 0.0176 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0161 - rmse: 0.0161 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0163 - rmse: 0.0163 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0158 - rmse: 0.0158 - val_loss: 0.1104 - val_rmse: 0.1104\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1097 - val_rmse: 0.1097\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0155 - rmse: 0.0155 - val_loss: 0.1135 - val_rmse: 0.1135\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0161 - rmse: 0.0161 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0151 - rmse: 0.0151 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0149 - rmse: 0.0149 - val_loss: 0.1111 - val_rmse: 0.1111\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0140 - rmse: 0.0140 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1107 - val_rmse: 0.1107\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0141 - rmse: 0.0141 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0128 - rmse: 0.0128 - val_loss: 0.1086 - val_rmse: 0.1086\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0131 - rmse: 0.0131 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1114 - val_rmse: 0.1114\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1124 - val_rmse: 0.1124\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1175 - val_rmse: 0.1175\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1163 - val_rmse: 0.1163\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0125 - rmse: 0.0125 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0121 - rmse: 0.0121 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1175 - val_rmse: 0.1175\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0125 - rmse: 0.0125 - val_loss: 0.1136 - val_rmse: 0.1136\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0116 - rmse: 0.0116 - val_loss: 0.1146 - val_rmse: 0.1146\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1132 - val_rmse: 0.1132\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1139 - val_rmse: 0.1139\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1155 - val_rmse: 0.1155\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1178 - val_rmse: 0.1178\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0121 - rmse: 0.0121 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1136 - val_rmse: 0.1136\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1143 - val_rmse: 0.1143\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1141 - val_rmse: 0.1141\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0109 - rmse: 0.0109Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1132 - val_rmse: 0.1132\n",
            "Epoch 00060: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  1  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 8s 206ms/step - loss: 0.0330 - rmse: 0.0330 - val_loss: 0.1110 - val_rmse: 0.1110\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0242 - rmse: 0.0242 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0210 - rmse: 0.0210 - val_loss: 0.1101 - val_rmse: 0.1101\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0181 - rmse: 0.0181 - val_loss: 0.1092 - val_rmse: 0.1092\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0165 - rmse: 0.0165 - val_loss: 0.1103 - val_rmse: 0.1103\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0151 - rmse: 0.0151 - val_loss: 0.1093 - val_rmse: 0.1093\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0155 - rmse: 0.0155 - val_loss: 0.1111 - val_rmse: 0.1111\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1087 - val_rmse: 0.1087\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0141 - rmse: 0.0141 - val_loss: 0.1097 - val_rmse: 0.1097\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1092 - val_rmse: 0.1092\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1092 - val_rmse: 0.1092\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0139 - rmse: 0.0139 - val_loss: 0.1095 - val_rmse: 0.1095\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0125 - rmse: 0.0125 - val_loss: 0.1118 - val_rmse: 0.1118\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1078 - val_rmse: 0.1078\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1112 - val_rmse: 0.1112\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1087 - val_rmse: 0.1087\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1090 - val_rmse: 0.1090\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1097 - val_rmse: 0.1097\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0162 - rmse: 0.0162 - val_loss: 0.1090 - val_rmse: 0.1090\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0127 - rmse: 0.0127 - val_loss: 0.1089 - val_rmse: 0.1089\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0121 - rmse: 0.0121 - val_loss: 0.1090 - val_rmse: 0.1090\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1085 - val_rmse: 0.1085\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1091 - val_rmse: 0.1091\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0121 - rmse: 0.0121 - val_loss: 0.1085 - val_rmse: 0.1085\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1068 - val_rmse: 0.1068\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1080 - val_rmse: 0.1080\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1085 - val_rmse: 0.1085\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1084 - val_rmse: 0.1084\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1075 - val_rmse: 0.1075\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1104 - val_rmse: 0.1104\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1059 - val_rmse: 0.1059\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1087 - val_rmse: 0.1087\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0116 - rmse: 0.0116 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1082 - val_rmse: 0.1082\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1069 - val_rmse: 0.1069\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1083 - val_rmse: 0.1083\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1065 - val_rmse: 0.1065\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1075 - val_rmse: 0.1075\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1073 - val_rmse: 0.1073\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1074 - val_rmse: 0.1074\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1063 - val_rmse: 0.1063\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1082 - val_rmse: 0.1082\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1080 - val_rmse: 0.1080\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1091 - val_rmse: 0.1091\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1076 - val_rmse: 0.1076\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1055 - val_rmse: 0.1055\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1079 - val_rmse: 0.1079\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1069 - val_rmse: 0.1069\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1045 - val_rmse: 0.1045\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1087 - val_rmse: 0.1087\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1076 - val_rmse: 0.1076\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1078 - val_rmse: 0.1078\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1069 - val_rmse: 0.1069\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1073 - val_rmse: 0.1073\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1087 - val_rmse: 0.1087\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1067 - val_rmse: 0.1067\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1084 - val_rmse: 0.1084\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1064 - val_rmse: 0.1064\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1091 - val_rmse: 0.1091\n",
            "Epoch 68/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 69/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1097 - val_rmse: 0.1097\n",
            "Epoch 70/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1073 - val_rmse: 0.1073\n",
            "Epoch 71/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1086 - val_rmse: 0.1086\n",
            "Epoch 72/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0081 - rmse: 0.0081 - val_loss: 0.1085 - val_rmse: 0.1085\n",
            "Epoch 73/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1095 - val_rmse: 0.1095\n",
            "Epoch 74/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1135 - val_rmse: 0.1135\n",
            "Epoch 75/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0258 - rmse: 0.0258 - val_loss: 0.1117 - val_rmse: 0.1117\n",
            "Epoch 76/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0145 - rmse: 0.0145 - val_loss: 0.1107 - val_rmse: 0.1107\n",
            "Epoch 77/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1095 - val_rmse: 0.1095\n",
            "Epoch 78/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1103 - val_rmse: 0.1103\n",
            "Epoch 79/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0109 - rmse: 0.0109Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1118 - val_rmse: 0.1118\n",
            "Epoch 00079: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  2  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 13s 323ms/step - loss: 0.0331 - rmse: 0.0331 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0221 - rmse: 0.0221 - val_loss: 0.1207 - val_rmse: 0.1207\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0184 - rmse: 0.0184 - val_loss: 0.1207 - val_rmse: 0.1207\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0161 - rmse: 0.0161 - val_loss: 0.1192 - val_rmse: 0.1192\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0161 - rmse: 0.0161 - val_loss: 0.1234 - val_rmse: 0.1234\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0176 - rmse: 0.0176 - val_loss: 0.1183 - val_rmse: 0.1183\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1195 - val_rmse: 0.1195\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1183 - val_rmse: 0.1183\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0125 - rmse: 0.0125 - val_loss: 0.1192 - val_rmse: 0.1192\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1180 - val_rmse: 0.1180\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1187 - val_rmse: 0.1187\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1174 - val_rmse: 0.1174\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1193 - val_rmse: 0.1193\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1183 - val_rmse: 0.1183\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1169 - val_rmse: 0.1169\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1154 - val_rmse: 0.1154\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1182 - val_rmse: 0.1182\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1182 - val_rmse: 0.1182\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1187 - val_rmse: 0.1187\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1192 - val_rmse: 0.1192\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1149 - val_rmse: 0.1149\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1146 - val_rmse: 0.1146\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1187 - val_rmse: 0.1187\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1149 - val_rmse: 0.1149\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1131 - val_rmse: 0.1131\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1139 - val_rmse: 0.1139\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 97ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1147 - val_rmse: 0.1147\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1135 - val_rmse: 0.1135\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1147 - val_rmse: 0.1147\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1146 - val_rmse: 0.1146\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0089 - rmse: 0.0089 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1133 - val_rmse: 0.1133\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0089 - rmse: 0.0089 - val_loss: 0.1141 - val_rmse: 0.1141\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0121 - rmse: 0.0121 - val_loss: 0.1197 - val_rmse: 0.1197\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0203 - rmse: 0.0203 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0163 - rmse: 0.0163 - val_loss: 0.1143 - val_rmse: 0.1143\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1155 - val_rmse: 0.1155\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1135 - val_rmse: 0.1135\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1141 - val_rmse: 0.1141\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0093 - rmse: 0.0093Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1182 - val_rmse: 0.1182\n",
            "Epoch 00062: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  3  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 8s 206ms/step - loss: 0.0395 - rmse: 0.0395 - val_loss: 0.1109 - val_rmse: 0.1109\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0309 - rmse: 0.0309 - val_loss: 0.1116 - val_rmse: 0.1116\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0262 - rmse: 0.0262 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0233 - rmse: 0.0233 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0214 - rmse: 0.0214 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0188 - rmse: 0.0188 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0172 - rmse: 0.0172 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0168 - rmse: 0.0168 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0154 - rmse: 0.0154 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0163 - rmse: 0.0163 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0153 - rmse: 0.0153 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0142 - rmse: 0.0142 - val_loss: 0.1143 - val_rmse: 0.1143\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0142 - rmse: 0.0142 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0131 - rmse: 0.0131 - val_loss: 0.1139 - val_rmse: 0.1139\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0136 - rmse: 0.0136 - val_loss: 0.1146 - val_rmse: 0.1146\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0125 - rmse: 0.0125 - val_loss: 0.1146 - val_rmse: 0.1146\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0125 - rmse: 0.0125 - val_loss: 0.1175 - val_rmse: 0.1175\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0141 - rmse: 0.0141 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0127 - rmse: 0.0127 - val_loss: 0.1136 - val_rmse: 0.1136\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0116 - rmse: 0.0116 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1135 - val_rmse: 0.1135\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1147 - val_rmse: 0.1147\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1154 - val_rmse: 0.1154\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1155 - val_rmse: 0.1155\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1147 - val_rmse: 0.1147\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1143 - val_rmse: 0.1143\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1155 - val_rmse: 0.1155\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1146 - val_rmse: 0.1146\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1143 - val_rmse: 0.1143\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1143 - val_rmse: 0.1143\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1135 - val_rmse: 0.1135\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1133 - val_rmse: 0.1133\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1146 - val_rmse: 0.1146\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1133 - val_rmse: 0.1133\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0104 - rmse: 0.0104Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 00059: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  4  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0351 - rmse: 0.0351 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0250 - rmse: 0.0250 - val_loss: 0.1106 - val_rmse: 0.1106\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0207 - rmse: 0.0207 - val_loss: 0.1079 - val_rmse: 0.1079\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0181 - rmse: 0.0181 - val_loss: 0.1078 - val_rmse: 0.1078\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0163 - rmse: 0.0163 - val_loss: 0.1082 - val_rmse: 0.1082\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0157 - rmse: 0.0157 - val_loss: 0.1077 - val_rmse: 0.1077\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0146 - rmse: 0.0146 - val_loss: 0.1081 - val_rmse: 0.1081\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0159 - rmse: 0.0159 - val_loss: 0.1076 - val_rmse: 0.1076\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0153 - rmse: 0.0153 - val_loss: 0.1075 - val_rmse: 0.1075\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.1077 - val_rmse: 0.1077\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1085 - val_rmse: 0.1085\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1066 - val_rmse: 0.1066\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1086 - val_rmse: 0.1086\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1075 - val_rmse: 0.1075\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1079 - val_rmse: 0.1079\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1043 - val_rmse: 0.1043\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1078 - val_rmse: 0.1078\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1054 - val_rmse: 0.1054\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1060 - val_rmse: 0.1060\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1065 - val_rmse: 0.1065\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1115 - val_rmse: 0.1115\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0176 - rmse: 0.0176 - val_loss: 0.1133 - val_rmse: 0.1133\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0340 - rmse: 0.0340 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0309 - rmse: 0.0309 - val_loss: 0.1063 - val_rmse: 0.1063\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0216 - rmse: 0.0216 - val_loss: 0.1060 - val_rmse: 0.1060\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0171 - rmse: 0.0171 - val_loss: 0.1059 - val_rmse: 0.1059\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0184 - rmse: 0.0184 - val_loss: 0.1066 - val_rmse: 0.1066\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0161 - rmse: 0.0161 - val_loss: 0.1060 - val_rmse: 0.1060\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0156 - rmse: 0.0156 - val_loss: 0.1042 - val_rmse: 0.1042\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0155 - rmse: 0.0155 - val_loss: 0.1045 - val_rmse: 0.1045\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0136 - rmse: 0.0136 - val_loss: 0.1034 - val_rmse: 0.1034\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1037 - val_rmse: 0.1037\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0135 - rmse: 0.0135 - val_loss: 0.1049 - val_rmse: 0.1049\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0142 - rmse: 0.0142 - val_loss: 0.1042 - val_rmse: 0.1042\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1030 - val_rmse: 0.1030\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0128 - rmse: 0.0128 - val_loss: 0.1059 - val_rmse: 0.1059\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0131 - rmse: 0.0131 - val_loss: 0.1047 - val_rmse: 0.1047\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1038 - val_rmse: 0.1038\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1037 - val_rmse: 0.1037\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1038 - val_rmse: 0.1038\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0116 - rmse: 0.0116 - val_loss: 0.1047 - val_rmse: 0.1047\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1042 - val_rmse: 0.1042\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1053 - val_rmse: 0.1053\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1036 - val_rmse: 0.1036\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1026 - val_rmse: 0.1026\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1034 - val_rmse: 0.1034\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1039 - val_rmse: 0.1039\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1036 - val_rmse: 0.1036\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1037 - val_rmse: 0.1037\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1030 - val_rmse: 0.1030\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1037 - val_rmse: 0.1037\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1045 - val_rmse: 0.1045\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1045 - val_rmse: 0.1045\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1041 - val_rmse: 0.1041\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1057 - val_rmse: 0.1057\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0120 - rmse: 0.0120Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1042 - val_rmse: 0.1042\n",
            "Epoch 00057: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  5  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0343 - rmse: 0.0343 - val_loss: 0.1104 - val_rmse: 0.1104\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0252 - rmse: 0.0252 - val_loss: 0.1109 - val_rmse: 0.1109\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0216 - rmse: 0.0216 - val_loss: 0.1095 - val_rmse: 0.1095\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0198 - rmse: 0.0198 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0185 - rmse: 0.0185 - val_loss: 0.1084 - val_rmse: 0.1084\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0189 - rmse: 0.0189 - val_loss: 0.1083 - val_rmse: 0.1083\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0187 - rmse: 0.0187 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0181 - rmse: 0.0181 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0158 - rmse: 0.0158 - val_loss: 0.1089 - val_rmse: 0.1089\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0158 - rmse: 0.0158 - val_loss: 0.1066 - val_rmse: 0.1066\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0153 - rmse: 0.0153 - val_loss: 0.1065 - val_rmse: 0.1065\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.1065 - val_rmse: 0.1065\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0143 - rmse: 0.0143 - val_loss: 0.1062 - val_rmse: 0.1062\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1061 - val_rmse: 0.1061\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0135 - rmse: 0.0135 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1059 - val_rmse: 0.1059\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0135 - rmse: 0.0135 - val_loss: 0.1059 - val_rmse: 0.1059\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1082 - val_rmse: 0.1082\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0136 - rmse: 0.0136 - val_loss: 0.1060 - val_rmse: 0.1060\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1050 - val_rmse: 0.1050\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1058 - val_rmse: 0.1058\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1066 - val_rmse: 0.1066\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1069 - val_rmse: 0.1069\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0142 - rmse: 0.0142 - val_loss: 0.1084 - val_rmse: 0.1084\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1053 - val_rmse: 0.1053\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0127 - rmse: 0.0127 - val_loss: 0.1064 - val_rmse: 0.1064\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1055 - val_rmse: 0.1055\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0127 - rmse: 0.0127 - val_loss: 0.1041 - val_rmse: 0.1041\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1065 - val_rmse: 0.1065\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1059 - val_rmse: 0.1059\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1066 - val_rmse: 0.1066\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1045 - val_rmse: 0.1045\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1058 - val_rmse: 0.1058\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1062 - val_rmse: 0.1062\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1074 - val_rmse: 0.1074\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1066 - val_rmse: 0.1066\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1057 - val_rmse: 0.1057\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1047 - val_rmse: 0.1047\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1085 - val_rmse: 0.1085\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1079 - val_rmse: 0.1079\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0121 - rmse: 0.0121 - val_loss: 0.1068 - val_rmse: 0.1068\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1086 - val_rmse: 0.1086\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1078 - val_rmse: 0.1078\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1066 - val_rmse: 0.1066\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1093 - val_rmse: 0.1093\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1080 - val_rmse: 0.1080\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1081 - val_rmse: 0.1081\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1091 - val_rmse: 0.1091\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1065 - val_rmse: 0.1065\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1091 - val_rmse: 0.1091\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1093 - val_rmse: 0.1093\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1068 - val_rmse: 0.1068\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1063 - val_rmse: 0.1063\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1080 - val_rmse: 0.1080\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1075 - val_rmse: 0.1075\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1075 - val_rmse: 0.1075\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1069 - val_rmse: 0.1069\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1056 - val_rmse: 0.1056\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1057 - val_rmse: 0.1057\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1076 - val_rmse: 0.1076\n",
            "Epoch 68/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1077 - val_rmse: 0.1077\n",
            "Epoch 69/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1079 - val_rmse: 0.1079\n",
            "Epoch 70/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1088 - val_rmse: 0.1088\n",
            "Epoch 71/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 72/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1081 - val_rmse: 0.1081\n",
            "Epoch 73/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1062 - val_rmse: 0.1062\n",
            "Epoch 74/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1087 - val_rmse: 0.1087\n",
            "Epoch 75/200\n",
            "40/40 [==============================] - 4s 100ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1078 - val_rmse: 0.1078\n",
            "Epoch 76/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1062 - val_rmse: 0.1062\n",
            "Epoch 77/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1046 - val_rmse: 0.1046\n",
            "Epoch 78/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1053 - val_rmse: 0.1053\n",
            "Epoch 79/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1067 - val_rmse: 0.1067\n",
            "Epoch 80/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1073 - val_rmse: 0.1073\n",
            "Epoch 81/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1065 - val_rmse: 0.1065\n",
            "Epoch 82/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1081 - val_rmse: 0.1081\n",
            "Epoch 83/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1065 - val_rmse: 0.1065\n",
            "Epoch 84/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 85/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0097 - rmse: 0.0097Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1075 - val_rmse: 0.1075\n",
            "Epoch 00085: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  6  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0327 - rmse: 0.0327 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0217 - rmse: 0.0217 - val_loss: 0.1119 - val_rmse: 0.1119\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0177 - rmse: 0.0177 - val_loss: 0.1117 - val_rmse: 0.1117\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0152 - rmse: 0.0152 - val_loss: 0.1133 - val_rmse: 0.1133\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0149 - rmse: 0.0149 - val_loss: 0.1123 - val_rmse: 0.1123\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0143 - rmse: 0.0143 - val_loss: 0.1111 - val_rmse: 0.1111\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1115 - val_rmse: 0.1115\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1111 - val_rmse: 0.1111\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1092 - val_rmse: 0.1092\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1116 - val_rmse: 0.1116\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1093 - val_rmse: 0.1093\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1107 - val_rmse: 0.1107\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1095 - val_rmse: 0.1095\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1099 - val_rmse: 0.1099\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1104 - val_rmse: 0.1104\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1108 - val_rmse: 0.1108\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1097 - val_rmse: 0.1097\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1098 - val_rmse: 0.1098\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1104 - val_rmse: 0.1104\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1094 - val_rmse: 0.1094\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0183 - rmse: 0.0183 - val_loss: 0.1098 - val_rmse: 0.1098\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0154 - rmse: 0.0154 - val_loss: 0.1080 - val_rmse: 0.1080\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1082 - val_rmse: 0.1082\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1089 - val_rmse: 0.1089\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1080 - val_rmse: 0.1080\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1102 - val_rmse: 0.1102\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1064 - val_rmse: 0.1064\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1073 - val_rmse: 0.1073\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1088 - val_rmse: 0.1088\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1086 - val_rmse: 0.1086\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1056 - val_rmse: 0.1056\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0084 - rmse: 0.0084 - val_loss: 0.1095 - val_rmse: 0.1095\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1090 - val_rmse: 0.1090\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1074 - val_rmse: 0.1074\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1064 - val_rmse: 0.1064\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1085 - val_rmse: 0.1085\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1095 - val_rmse: 0.1095\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1078 - val_rmse: 0.1078\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1069 - val_rmse: 0.1069\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1074 - val_rmse: 0.1074\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1081 - val_rmse: 0.1081\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1076 - val_rmse: 0.1076\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1074 - val_rmse: 0.1074\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1080 - val_rmse: 0.1080\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1052 - val_rmse: 0.1052\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0085 - rmse: 0.0085 - val_loss: 0.1063 - val_rmse: 0.1063\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1048 - val_rmse: 0.1048\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0083 - rmse: 0.0083 - val_loss: 0.1073 - val_rmse: 0.1073\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1076 - val_rmse: 0.1076\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1044 - val_rmse: 0.1044\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1045 - val_rmse: 0.1045\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1086 - val_rmse: 0.1086\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0142 - rmse: 0.0142 - val_loss: 0.1060 - val_rmse: 0.1060\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1047 - val_rmse: 0.1047\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1065 - val_rmse: 0.1065\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1067 - val_rmse: 0.1067\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0090 - rmse: 0.0090Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1061 - val_rmse: 0.1061\n",
            "Epoch 00063: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  7  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0360 - rmse: 0.0360 - val_loss: 0.1167 - val_rmse: 0.1167\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0240 - rmse: 0.0240 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0195 - rmse: 0.0195 - val_loss: 0.1193 - val_rmse: 0.1193\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0178 - rmse: 0.0178 - val_loss: 0.1194 - val_rmse: 0.1194\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0157 - rmse: 0.0157 - val_loss: 0.1211 - val_rmse: 0.1211\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0143 - rmse: 0.0143 - val_loss: 0.1167 - val_rmse: 0.1167\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.1218 - val_rmse: 0.1218\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0144 - rmse: 0.0144 - val_loss: 0.1191 - val_rmse: 0.1191\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0128 - rmse: 0.0128 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0128 - rmse: 0.0128 - val_loss: 0.1186 - val_rmse: 0.1186\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0128 - rmse: 0.0128 - val_loss: 0.1177 - val_rmse: 0.1177\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1176 - val_rmse: 0.1176\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1133 - val_rmse: 0.1133\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1200 - val_rmse: 0.1200\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1229 - val_rmse: 0.1229\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1190 - val_rmse: 0.1190\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1187 - val_rmse: 0.1187\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1175 - val_rmse: 0.1175\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1198 - val_rmse: 0.1198\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1169 - val_rmse: 0.1169\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1149 - val_rmse: 0.1149\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1195 - val_rmse: 0.1195\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1177 - val_rmse: 0.1177\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1208 - val_rmse: 0.1208\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1174 - val_rmse: 0.1174\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1209 - val_rmse: 0.1209\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1182 - val_rmse: 0.1182\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1200 - val_rmse: 0.1200\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1194 - val_rmse: 0.1194\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0089 - rmse: 0.0089 - val_loss: 0.1213 - val_rmse: 0.1213\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0085 - rmse: 0.0085 - val_loss: 0.1186 - val_rmse: 0.1186\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1163 - val_rmse: 0.1163\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0089 - rmse: 0.0089 - val_loss: 0.1176 - val_rmse: 0.1176\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0150 - rmse: 0.0150 - val_loss: 0.1188 - val_rmse: 0.1188\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1212 - val_rmse: 0.1212\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1203 - val_rmse: 0.1203\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0089 - rmse: 0.0089 - val_loss: 0.1218 - val_rmse: 0.1218\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1211 - val_rmse: 0.1211\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1243 - val_rmse: 0.1243\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0089 - rmse: 0.0089 - val_loss: 0.1230 - val_rmse: 0.1230\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1213 - val_rmse: 0.1213\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0102 - rmse: 0.0102Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1174 - val_rmse: 0.1174\n",
            "Epoch 00059: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  8  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0327 - rmse: 0.0327 - val_loss: 0.1122 - val_rmse: 0.1122\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0229 - rmse: 0.0229 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0187 - rmse: 0.0187 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0165 - rmse: 0.0165 - val_loss: 0.1143 - val_rmse: 0.1143\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0154 - rmse: 0.0154 - val_loss: 0.1135 - val_rmse: 0.1135\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0145 - rmse: 0.0145 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0136 - rmse: 0.0136 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1131 - val_rmse: 0.1131\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1147 - val_rmse: 0.1147\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1139 - val_rmse: 0.1139\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1146 - val_rmse: 0.1146\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1122 - val_rmse: 0.1122\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1136 - val_rmse: 0.1136\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1146 - val_rmse: 0.1146\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1123 - val_rmse: 0.1123\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0136 - rmse: 0.0136 - val_loss: 0.1141 - val_rmse: 0.1141\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1132 - val_rmse: 0.1132\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1132 - val_rmse: 0.1132\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0098 - rmse: 0.0098Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 00053: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  9  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0271 - rmse: 0.0271 - val_loss: 0.1095 - val_rmse: 0.1095\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0206 - rmse: 0.0206 - val_loss: 0.1089 - val_rmse: 0.1089\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0176 - rmse: 0.0176 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0159 - rmse: 0.0159 - val_loss: 0.1104 - val_rmse: 0.1104\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0143 - rmse: 0.0143 - val_loss: 0.1102 - val_rmse: 0.1102\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1103 - val_rmse: 0.1103\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1116 - val_rmse: 0.1116\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0139 - rmse: 0.0139 - val_loss: 0.1122 - val_rmse: 0.1122\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0127 - rmse: 0.0127 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1110 - val_rmse: 0.1110\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1124 - val_rmse: 0.1124\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1114 - val_rmse: 0.1114\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1141 - val_rmse: 0.1141\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1091 - val_rmse: 0.1091\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1116 - val_rmse: 0.1116\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1119 - val_rmse: 0.1119\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1112 - val_rmse: 0.1112\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1109 - val_rmse: 0.1109\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1136 - val_rmse: 0.1136\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1124 - val_rmse: 0.1124\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1097 - val_rmse: 0.1097\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1123 - val_rmse: 0.1123\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1111 - val_rmse: 0.1111\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1105 - val_rmse: 0.1105\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1111 - val_rmse: 0.1111\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1108 - val_rmse: 0.1108\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1102 - val_rmse: 0.1102\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1100 - val_rmse: 0.1100\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1122 - val_rmse: 0.1122\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1091 - val_rmse: 0.1091\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1099 - val_rmse: 0.1099\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0477 - rmse: 0.0477 - val_loss: 0.1225 - val_rmse: 0.1225\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0378 - rmse: 0.0378 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0281 - rmse: 0.0281 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0205 - rmse: 0.0205 - val_loss: 0.1117 - val_rmse: 0.1117\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0174 - rmse: 0.0174 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0169 - rmse: 0.0169 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0220 - rmse: 0.0220 - val_loss: 0.1060 - val_rmse: 0.1060\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0185 - rmse: 0.0185 - val_loss: 0.1088 - val_rmse: 0.1088\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0250 - rmse: 0.0250 - val_loss: 0.1091 - val_rmse: 0.1091\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0244 - rmse: 0.0244 - val_loss: 0.1107 - val_rmse: 0.1107\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0187 - rmse: 0.0187 - val_loss: 0.1077 - val_rmse: 0.1077\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0168 - rmse: 0.0168 - val_loss: 0.1066 - val_rmse: 0.1066\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1061 - val_rmse: 0.1061\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0139 - rmse: 0.0139 - val_loss: 0.1084 - val_rmse: 0.1084\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0138 - rmse: 0.0138Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1083 - val_rmse: 0.1083\n",
            "Epoch 00054: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  10  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0306 - rmse: 0.0306 - val_loss: 0.1179 - val_rmse: 0.1179\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0192 - rmse: 0.0192 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1155 - val_rmse: 0.1155\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1135 - val_rmse: 0.1135\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1133 - val_rmse: 0.1133\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1131 - val_rmse: 0.1131\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1110 - val_rmse: 0.1110\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0089 - rmse: 0.0089 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1111 - val_rmse: 0.1111\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0083 - rmse: 0.0083 - val_loss: 0.1107 - val_rmse: 0.1107\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0469 - rmse: 0.0469 - val_loss: 0.1343 - val_rmse: 0.1343\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.3124 - rmse: 0.3124 - val_loss: 0.3084 - val_rmse: 0.3084\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2830 - rmse: 0.2830 - val_loss: 0.2691 - val_rmse: 0.2691\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2675 - rmse: 0.2675 - val_loss: 0.2754 - val_rmse: 0.2754\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2666 - rmse: 0.2666 - val_loss: 0.2672 - val_rmse: 0.2672\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2628 - rmse: 0.2628 - val_loss: 0.2628 - val_rmse: 0.2628\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2556 - rmse: 0.2556 - val_loss: 0.2638 - val_rmse: 0.2638\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2475 - rmse: 0.2475 - val_loss: 0.2640 - val_rmse: 0.2640\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2463 - rmse: 0.2463 - val_loss: 0.2548 - val_rmse: 0.2548\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2368 - rmse: 0.2368 - val_loss: 0.2463 - val_rmse: 0.2463\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2360 - rmse: 0.2360 - val_loss: 0.2516 - val_rmse: 0.2516\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2338 - rmse: 0.2338 - val_loss: 0.2449 - val_rmse: 0.2449\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2267 - rmse: 0.2267 - val_loss: 0.2391 - val_rmse: 0.2391\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2252 - rmse: 0.2252 - val_loss: 0.2418 - val_rmse: 0.2418\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2229 - rmse: 0.2229 - val_loss: 0.2431 - val_rmse: 0.2431\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2178 - rmse: 0.2178 - val_loss: 0.2317 - val_rmse: 0.2317\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2131 - rmse: 0.2131 - val_loss: 0.2275 - val_rmse: 0.2275\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2118 - rmse: 0.2118 - val_loss: 0.2245 - val_rmse: 0.2245\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2087 - rmse: 0.2087 - val_loss: 0.2248 - val_rmse: 0.2248\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.2081 - rmse: 0.2081 - val_loss: 0.2179 - val_rmse: 0.2179\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.2013 - rmse: 0.2013 - val_loss: 0.2274 - val_rmse: 0.2274\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 95ms/step - loss: 0.2005 - rmse: 0.2005 - val_loss: 0.2184 - val_rmse: 0.2184\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1988 - rmse: 0.1988 - val_loss: 0.2152 - val_rmse: 0.2152\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1919 - rmse: 0.1919 - val_loss: 0.2142 - val_rmse: 0.2142\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1877 - rmse: 0.1877 - val_loss: 0.2160 - val_rmse: 0.2160\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1849 - rmse: 0.1849 - val_loss: 0.2079 - val_rmse: 0.2079\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1830 - rmse: 0.1830 - val_loss: 0.2111 - val_rmse: 0.2111\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1793 - rmse: 0.1793 - val_loss: 0.2084 - val_rmse: 0.2084\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1756 - rmse: 0.1756 - val_loss: 0.2054 - val_rmse: 0.2054\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1797 - rmse: 0.1797 - val_loss: 0.2082 - val_rmse: 0.2082\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1762 - rmse: 0.1762 - val_loss: 0.1953 - val_rmse: 0.1953\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1717 - rmse: 0.1717 - val_loss: 0.1968 - val_rmse: 0.1968\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1696 - rmse: 0.1696 - val_loss: 0.1890 - val_rmse: 0.1890\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1698 - rmse: 0.1698 - val_loss: 0.1847 - val_rmse: 0.1847\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1642 - rmse: 0.1642 - val_loss: 0.1950 - val_rmse: 0.1950\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1611 - rmse: 0.1611 - val_loss: 0.1921 - val_rmse: 0.1921\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1633 - rmse: 0.1633 - val_loss: 0.1807 - val_rmse: 0.1807\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1635 - rmse: 0.1635 - val_loss: 0.1905 - val_rmse: 0.1905\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1546 - rmse: 0.1546 - val_loss: 0.1868 - val_rmse: 0.1868\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1582 - rmse: 0.1582 - val_loss: 0.1869 - val_rmse: 0.1869\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1543 - rmse: 0.1543 - val_loss: 0.1842 - val_rmse: 0.1842\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.1535 - rmse: 0.1535 - val_loss: 0.1848 - val_rmse: 0.1848\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1546 - rmse: 0.1546Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.1546 - rmse: 0.1546 - val_loss: 0.1840 - val_rmse: 0.1840\n",
            "Epoch 00067: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  11  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 8s 200ms/step - loss: 0.0363 - rmse: 0.0363 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0327 - rmse: 0.0327 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0312 - rmse: 0.0312 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0302 - rmse: 0.0302 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0296 - rmse: 0.0296 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0289 - rmse: 0.0289 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0282 - rmse: 0.0282 - val_loss: 0.1149 - val_rmse: 0.1149\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0278 - rmse: 0.0278 - val_loss: 0.1149 - val_rmse: 0.1149\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0272 - rmse: 0.0272 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0269 - rmse: 0.0269 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0266 - rmse: 0.0266 - val_loss: 0.1155 - val_rmse: 0.1155\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0263 - rmse: 0.0263 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0258 - rmse: 0.0258 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0257 - rmse: 0.0257 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0253 - rmse: 0.0253 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0250 - rmse: 0.0250 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0248 - rmse: 0.0248 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0246 - rmse: 0.0246 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0243 - rmse: 0.0243 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0241 - rmse: 0.0241 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0239 - rmse: 0.0239 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0237 - rmse: 0.0237 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0237 - rmse: 0.0237 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0233 - rmse: 0.0233 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0232 - rmse: 0.0232 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0230 - rmse: 0.0230 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0228 - rmse: 0.0228 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0227 - rmse: 0.0227 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0225 - rmse: 0.0225 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0222 - rmse: 0.0222 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0223 - rmse: 0.0223 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0221 - rmse: 0.0221 - val_loss: 0.1167 - val_rmse: 0.1167\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0221 - rmse: 0.0221 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0217 - rmse: 0.0217 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0216 - rmse: 0.0216 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0215 - rmse: 0.0215 - val_loss: 0.1169 - val_rmse: 0.1169\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0214 - rmse: 0.0214 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0213 - rmse: 0.0213 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0211 - rmse: 0.0211 - val_loss: 0.1167 - val_rmse: 0.1167\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0210 - rmse: 0.0210 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0208 - rmse: 0.0208 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0208 - rmse: 0.0208 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0209 - rmse: 0.0209 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0206 - rmse: 0.0206 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0203 - rmse: 0.0203 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0203 - rmse: 0.0203 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0203 - rmse: 0.0203 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0201 - rmse: 0.0201 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0202 - rmse: 0.0202 - val_loss: 0.1175 - val_rmse: 0.1175\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0201 - rmse: 0.0201 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0199 - rmse: 0.0199 - val_loss: 0.1171 - val_rmse: 0.1171\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0198 - rmse: 0.0198 - val_loss: 0.1174 - val_rmse: 0.1174\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0196 - rmse: 0.0196 - val_loss: 0.1176 - val_rmse: 0.1176\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0195 - rmse: 0.0195 - val_loss: 0.1176 - val_rmse: 0.1176\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0194 - rmse: 0.0194 - val_loss: 0.1178 - val_rmse: 0.1178\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0194 - rmse: 0.0194 - val_loss: 0.1179 - val_rmse: 0.1179\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0193 - rmse: 0.0193 - val_loss: 0.1180 - val_rmse: 0.1180\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0192 - rmse: 0.0192 - val_loss: 0.1177 - val_rmse: 0.1177\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0190 - rmse: 0.0190 - val_loss: 0.1179 - val_rmse: 0.1179\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0189 - rmse: 0.0189 - val_loss: 0.1178 - val_rmse: 0.1178\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0190 - rmse: 0.0190 - val_loss: 0.1177 - val_rmse: 0.1177\n",
            "Epoch 62/200\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0190 - rmse: 0.0190Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0189 - rmse: 0.0189 - val_loss: 0.1178 - val_rmse: 0.1178\n",
            "Epoch 00062: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  12  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0346 - rmse: 0.0346 - val_loss: 0.1115 - val_rmse: 0.1115\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0297 - rmse: 0.0297 - val_loss: 0.1115 - val_rmse: 0.1115\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0276 - rmse: 0.0276 - val_loss: 0.1117 - val_rmse: 0.1117\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0262 - rmse: 0.0262 - val_loss: 0.1115 - val_rmse: 0.1115\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0251 - rmse: 0.0251 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0242 - rmse: 0.0242 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0235 - rmse: 0.0235 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0227 - rmse: 0.0227 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0220 - rmse: 0.0220 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0215 - rmse: 0.0215 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0210 - rmse: 0.0210 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0207 - rmse: 0.0207 - val_loss: 0.1131 - val_rmse: 0.1131\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0203 - rmse: 0.0203 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0198 - rmse: 0.0198 - val_loss: 0.1132 - val_rmse: 0.1132\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0196 - rmse: 0.0196 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0193 - rmse: 0.0193 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0190 - rmse: 0.0190 - val_loss: 0.1136 - val_rmse: 0.1136\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0187 - rmse: 0.0187 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0185 - rmse: 0.0185 - val_loss: 0.1139 - val_rmse: 0.1139\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0183 - rmse: 0.0183 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0181 - rmse: 0.0181 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0180 - rmse: 0.0180 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0176 - rmse: 0.0176 - val_loss: 0.1143 - val_rmse: 0.1143\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0175 - rmse: 0.0175 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0172 - rmse: 0.0172 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0172 - rmse: 0.0172 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0171 - rmse: 0.0171 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0168 - rmse: 0.0168 - val_loss: 0.1144 - val_rmse: 0.1144\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0166 - rmse: 0.0166 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0165 - rmse: 0.0165 - val_loss: 0.1149 - val_rmse: 0.1149\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0164 - rmse: 0.0164 - val_loss: 0.1147 - val_rmse: 0.1147\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0162 - rmse: 0.0162 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0162 - rmse: 0.0162 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0160 - rmse: 0.0160 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0158 - rmse: 0.0158 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0157 - rmse: 0.0157 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0157 - rmse: 0.0157 - val_loss: 0.1151 - val_rmse: 0.1151\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0155 - rmse: 0.0155 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0156 - rmse: 0.0156 - val_loss: 0.1154 - val_rmse: 0.1154\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0155 - rmse: 0.0155 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0153 - rmse: 0.0153 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0153 - rmse: 0.0153 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0150 - rmse: 0.0150 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0150 - rmse: 0.0150 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0149 - rmse: 0.0149 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0146 - rmse: 0.0146 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0145 - rmse: 0.0145 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0145 - rmse: 0.0145 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0143 - rmse: 0.0143 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0143 - rmse: 0.0143 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0142 - rmse: 0.0142 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0141 - rmse: 0.0141 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0140 - rmse: 0.0140 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0141 - rmse: 0.0141 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0141 - rmse: 0.0141 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0139 - rmse: 0.0139 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0139 - rmse: 0.0139 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0135 - rmse: 0.0135 - val_loss: 0.1163 - val_rmse: 0.1163\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0136 - rmse: 0.0136 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 68/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 69/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1163 - val_rmse: 0.1163\n",
            "Epoch 70/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 71/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 72/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 73/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 74/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1167 - val_rmse: 0.1167\n",
            "Epoch 75/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1167 - val_rmse: 0.1167\n",
            "Epoch 76/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0131 - rmse: 0.0131 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 77/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1169 - val_rmse: 0.1169\n",
            "Epoch 78/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 79/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0128 - rmse: 0.0128 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 80/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 81/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 82/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0125 - rmse: 0.0125 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 83/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 84/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 85/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1171 - val_rmse: 0.1171\n",
            "Epoch 86/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0125 - rmse: 0.0125 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 87/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0125 - rmse: 0.0125 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 88/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 89/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 90/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 91/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 92/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1171 - val_rmse: 0.1171\n",
            "Epoch 93/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0121 - rmse: 0.0121 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 94/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 95/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0121 - rmse: 0.0121 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 96/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 97/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1171 - val_rmse: 0.1171\n",
            "Epoch 98/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 99/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 100/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 101/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1170 - val_rmse: 0.1170\n",
            "Epoch 102/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1174 - val_rmse: 0.1174\n",
            "Epoch 103/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1175 - val_rmse: 0.1175\n",
            "Epoch 104/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0118 - rmse: 0.0118Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 00104: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  13  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0668 - rmse: 0.0668 - val_loss: 0.1364 - val_rmse: 0.1364\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0532 - rmse: 0.0532 - val_loss: 0.1345 - val_rmse: 0.1345\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0477 - rmse: 0.0477 - val_loss: 0.1336 - val_rmse: 0.1336\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0447 - rmse: 0.0447 - val_loss: 0.1329 - val_rmse: 0.1329\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0422 - rmse: 0.0422 - val_loss: 0.1328 - val_rmse: 0.1328\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0403 - rmse: 0.0403 - val_loss: 0.1324 - val_rmse: 0.1324\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0388 - rmse: 0.0388 - val_loss: 0.1319 - val_rmse: 0.1319\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0375 - rmse: 0.0375 - val_loss: 0.1320 - val_rmse: 0.1320\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0363 - rmse: 0.0363 - val_loss: 0.1317 - val_rmse: 0.1317\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0354 - rmse: 0.0354 - val_loss: 0.1314 - val_rmse: 0.1314\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0345 - rmse: 0.0345 - val_loss: 0.1314 - val_rmse: 0.1314\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0337 - rmse: 0.0337 - val_loss: 0.1307 - val_rmse: 0.1307\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0331 - rmse: 0.0331 - val_loss: 0.1312 - val_rmse: 0.1312\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0324 - rmse: 0.0324 - val_loss: 0.1305 - val_rmse: 0.1305\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0316 - rmse: 0.0316 - val_loss: 0.1300 - val_rmse: 0.1300\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0311 - rmse: 0.0311 - val_loss: 0.1304 - val_rmse: 0.1304\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0306 - rmse: 0.0306 - val_loss: 0.1301 - val_rmse: 0.1301\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0301 - rmse: 0.0301 - val_loss: 0.1301 - val_rmse: 0.1301\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0296 - rmse: 0.0296 - val_loss: 0.1300 - val_rmse: 0.1300\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0291 - rmse: 0.0291 - val_loss: 0.1297 - val_rmse: 0.1297\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0288 - rmse: 0.0288 - val_loss: 0.1297 - val_rmse: 0.1297\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0282 - rmse: 0.0282 - val_loss: 0.1297 - val_rmse: 0.1297\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0278 - rmse: 0.0278 - val_loss: 0.1298 - val_rmse: 0.1298\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0276 - rmse: 0.0276 - val_loss: 0.1296 - val_rmse: 0.1296\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0270 - rmse: 0.0270 - val_loss: 0.1296 - val_rmse: 0.1296\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0266 - rmse: 0.0266 - val_loss: 0.1297 - val_rmse: 0.1297\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0264 - rmse: 0.0264 - val_loss: 0.1299 - val_rmse: 0.1299\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0259 - rmse: 0.0259 - val_loss: 0.1294 - val_rmse: 0.1294\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0256 - rmse: 0.0256 - val_loss: 0.1294 - val_rmse: 0.1294\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0252 - rmse: 0.0252 - val_loss: 0.1293 - val_rmse: 0.1293\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0249 - rmse: 0.0249 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0247 - rmse: 0.0247 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0243 - rmse: 0.0243 - val_loss: 0.1294 - val_rmse: 0.1294\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0241 - rmse: 0.0241 - val_loss: 0.1294 - val_rmse: 0.1294\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0237 - rmse: 0.0237 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0234 - rmse: 0.0234 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0231 - rmse: 0.0231 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0228 - rmse: 0.0228 - val_loss: 0.1293 - val_rmse: 0.1293\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0225 - rmse: 0.0225 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0223 - rmse: 0.0223 - val_loss: 0.1288 - val_rmse: 0.1288\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0221 - rmse: 0.0221 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0219 - rmse: 0.0219 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0215 - rmse: 0.0215 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0213 - rmse: 0.0213 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0213 - rmse: 0.0213 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0210 - rmse: 0.0210 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0208 - rmse: 0.0208 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0206 - rmse: 0.0206 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0204 - rmse: 0.0204 - val_loss: 0.1293 - val_rmse: 0.1293\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0203 - rmse: 0.0203 - val_loss: 0.1293 - val_rmse: 0.1293\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0200 - rmse: 0.0200 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0199 - rmse: 0.0199 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0197 - rmse: 0.0197 - val_loss: 0.1289 - val_rmse: 0.1289\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0196 - rmse: 0.0196 - val_loss: 0.1293 - val_rmse: 0.1293\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0194 - rmse: 0.0194 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0193 - rmse: 0.0193 - val_loss: 0.1289 - val_rmse: 0.1289\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0190 - rmse: 0.0190 - val_loss: 0.1294 - val_rmse: 0.1294\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0189 - rmse: 0.0189 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0187 - rmse: 0.0187 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0187 - rmse: 0.0187 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0184 - rmse: 0.0184 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0182 - rmse: 0.0182 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0181 - rmse: 0.0181 - val_loss: 0.1293 - val_rmse: 0.1293\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0179 - rmse: 0.0179 - val_loss: 0.1289 - val_rmse: 0.1289\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0179 - rmse: 0.0179 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0178 - rmse: 0.0178 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0175 - rmse: 0.0175 - val_loss: 0.1289 - val_rmse: 0.1289\n",
            "Epoch 68/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0174 - rmse: 0.0174 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 69/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0171 - rmse: 0.0171 - val_loss: 0.1286 - val_rmse: 0.1286\n",
            "Epoch 70/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0172 - rmse: 0.0172 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 71/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0169 - rmse: 0.0169 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 72/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0169 - rmse: 0.0169 - val_loss: 0.1289 - val_rmse: 0.1289\n",
            "Epoch 73/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0167 - rmse: 0.0167 - val_loss: 0.1288 - val_rmse: 0.1288\n",
            "Epoch 74/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0167 - rmse: 0.0167 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 75/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0166 - rmse: 0.0166 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 76/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0164 - rmse: 0.0164 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 77/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0162 - rmse: 0.0162 - val_loss: 0.1295 - val_rmse: 0.1295\n",
            "Epoch 78/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0160 - rmse: 0.0160 - val_loss: 0.1287 - val_rmse: 0.1287\n",
            "Epoch 79/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0160 - rmse: 0.0160 - val_loss: 0.1296 - val_rmse: 0.1296\n",
            "Epoch 80/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0158 - rmse: 0.0158 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 81/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0158 - rmse: 0.0158 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 82/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0157 - rmse: 0.0157 - val_loss: 0.1294 - val_rmse: 0.1294\n",
            "Epoch 83/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0156 - rmse: 0.0156 - val_loss: 0.1288 - val_rmse: 0.1288\n",
            "Epoch 84/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0153 - rmse: 0.0153 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 85/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0152 - rmse: 0.0152 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 86/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0152 - rmse: 0.0152 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 87/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0151 - rmse: 0.0151 - val_loss: 0.1289 - val_rmse: 0.1289\n",
            "Epoch 88/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0150 - rmse: 0.0150 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 89/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0149 - rmse: 0.0149 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 90/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 91/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0146 - rmse: 0.0146 - val_loss: 0.1289 - val_rmse: 0.1289\n",
            "Epoch 92/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0145 - rmse: 0.0145 - val_loss: 0.1293 - val_rmse: 0.1293\n",
            "Epoch 93/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0144 - rmse: 0.0144Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0144 - rmse: 0.0144 - val_loss: 0.1292 - val_rmse: 0.1292\n",
            "Epoch 00093: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  14  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0481 - rmse: 0.0481 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0385 - rmse: 0.0385 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0349 - rmse: 0.0349 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0327 - rmse: 0.0327 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0311 - rmse: 0.0311 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0293 - rmse: 0.0293 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0283 - rmse: 0.0283 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0272 - rmse: 0.0272 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0265 - rmse: 0.0265 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0254 - rmse: 0.0254 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0246 - rmse: 0.0246 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0241 - rmse: 0.0241 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0234 - rmse: 0.0234 - val_loss: 0.1180 - val_rmse: 0.1180\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0228 - rmse: 0.0228 - val_loss: 0.1174 - val_rmse: 0.1174\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0222 - rmse: 0.0222 - val_loss: 0.1178 - val_rmse: 0.1178\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0217 - rmse: 0.0217 - val_loss: 0.1177 - val_rmse: 0.1177\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0212 - rmse: 0.0212 - val_loss: 0.1176 - val_rmse: 0.1176\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0208 - rmse: 0.0208 - val_loss: 0.1180 - val_rmse: 0.1180\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0205 - rmse: 0.0205 - val_loss: 0.1181 - val_rmse: 0.1181\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0200 - rmse: 0.0200 - val_loss: 0.1186 - val_rmse: 0.1186\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0194 - rmse: 0.0194 - val_loss: 0.1182 - val_rmse: 0.1182\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0193 - rmse: 0.0193 - val_loss: 0.1196 - val_rmse: 0.1196\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0188 - rmse: 0.0188 - val_loss: 0.1192 - val_rmse: 0.1192\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0184 - rmse: 0.0184 - val_loss: 0.1187 - val_rmse: 0.1187\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0182 - rmse: 0.0182 - val_loss: 0.1191 - val_rmse: 0.1191\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0179 - rmse: 0.0179 - val_loss: 0.1197 - val_rmse: 0.1197\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0175 - rmse: 0.0175 - val_loss: 0.1196 - val_rmse: 0.1196\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0172 - rmse: 0.0172 - val_loss: 0.1196 - val_rmse: 0.1196\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0170 - rmse: 0.0170 - val_loss: 0.1193 - val_rmse: 0.1193\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0168 - rmse: 0.0168 - val_loss: 0.1195 - val_rmse: 0.1195\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0163 - rmse: 0.0163 - val_loss: 0.1200 - val_rmse: 0.1200\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0162 - rmse: 0.0162 - val_loss: 0.1199 - val_rmse: 0.1199\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0159 - rmse: 0.0159 - val_loss: 0.1202 - val_rmse: 0.1202\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0158 - rmse: 0.0158 - val_loss: 0.1201 - val_rmse: 0.1201\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0155 - rmse: 0.0155 - val_loss: 0.1202 - val_rmse: 0.1202\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0151 - rmse: 0.0151 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0150 - rmse: 0.0150 - val_loss: 0.1206 - val_rmse: 0.1206\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0149 - rmse: 0.0149 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.1205 - val_rmse: 0.1205\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0145 - rmse: 0.0145 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0144 - rmse: 0.0144 - val_loss: 0.1203 - val_rmse: 0.1203\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0140 - rmse: 0.0140 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0141 - rmse: 0.0141 - val_loss: 0.1205 - val_rmse: 0.1205\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1206 - val_rmse: 0.1206\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1205 - val_rmse: 0.1205\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1209 - val_rmse: 0.1209\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1205 - val_rmse: 0.1205\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1205 - val_rmse: 0.1205\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0128 - rmse: 0.0128 - val_loss: 0.1206 - val_rmse: 0.1206\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1205 - val_rmse: 0.1205\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0128 - rmse: 0.0128 - val_loss: 0.1207 - val_rmse: 0.1207\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0127 - rmse: 0.0127 - val_loss: 0.1207 - val_rmse: 0.1207\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1206 - val_rmse: 0.1206\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1211 - val_rmse: 0.1211\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1214 - val_rmse: 0.1214\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1210 - val_rmse: 0.1210\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0120 - rmse: 0.0120 - val_loss: 0.1210 - val_rmse: 0.1210\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1210 - val_rmse: 0.1210\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1209 - val_rmse: 0.1209\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1208 - val_rmse: 0.1208\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1209 - val_rmse: 0.1209\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1212 - val_rmse: 0.1212\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1212 - val_rmse: 0.1212\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1210 - val_rmse: 0.1210\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1211 - val_rmse: 0.1211\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1207 - val_rmse: 0.1207\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1213 - val_rmse: 0.1213\n",
            "Epoch 68/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1213 - val_rmse: 0.1213\n",
            "Epoch 69/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1212 - val_rmse: 0.1212\n",
            "Epoch 70/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1211 - val_rmse: 0.1211\n",
            "Epoch 71/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1213 - val_rmse: 0.1213\n",
            "Epoch 72/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1212 - val_rmse: 0.1212\n",
            "Epoch 73/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1207 - val_rmse: 0.1207\n",
            "Epoch 74/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1216 - val_rmse: 0.1216\n",
            "Epoch 75/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1208 - val_rmse: 0.1208\n",
            "Epoch 76/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1208 - val_rmse: 0.1208\n",
            "Epoch 77/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 78/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1209 - val_rmse: 0.1209\n",
            "Epoch 79/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1211 - val_rmse: 0.1211\n",
            "Epoch 80/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1203 - val_rmse: 0.1203\n",
            "Epoch 81/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1197 - val_rmse: 0.1197\n",
            "Epoch 82/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1209 - val_rmse: 0.1209\n",
            "Epoch 83/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1207 - val_rmse: 0.1207\n",
            "Epoch 84/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.1208 - val_rmse: 0.1208\n",
            "Epoch 85/200\n",
            "40/40 [==============================] - 4s 98ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1208 - val_rmse: 0.1208\n",
            "Epoch 86/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 87/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1211 - val_rmse: 0.1211\n",
            "Epoch 88/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1193 - val_rmse: 0.1193\n",
            "Epoch 89/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 90/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0086 - rmse: 0.0086Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1209 - val_rmse: 0.1209\n",
            "Epoch 00090: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  15  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0355 - rmse: 0.0355 - val_loss: 0.1280 - val_rmse: 0.1280\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0301 - rmse: 0.0301 - val_loss: 0.1264 - val_rmse: 0.1264\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0274 - rmse: 0.0274 - val_loss: 0.1257 - val_rmse: 0.1257\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0253 - rmse: 0.0253 - val_loss: 0.1250 - val_rmse: 0.1250\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0240 - rmse: 0.0240 - val_loss: 0.1246 - val_rmse: 0.1246\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0227 - rmse: 0.0227 - val_loss: 0.1248 - val_rmse: 0.1248\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0216 - rmse: 0.0216 - val_loss: 0.1241 - val_rmse: 0.1241\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0206 - rmse: 0.0206 - val_loss: 0.1242 - val_rmse: 0.1242\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0196 - rmse: 0.0196 - val_loss: 0.1241 - val_rmse: 0.1241\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0190 - rmse: 0.0190 - val_loss: 0.1242 - val_rmse: 0.1242\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0182 - rmse: 0.0182 - val_loss: 0.1243 - val_rmse: 0.1243\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0177 - rmse: 0.0177 - val_loss: 0.1244 - val_rmse: 0.1244\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0170 - rmse: 0.0170 - val_loss: 0.1240 - val_rmse: 0.1240\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0167 - rmse: 0.0167 - val_loss: 0.1242 - val_rmse: 0.1242\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0161 - rmse: 0.0161 - val_loss: 0.1238 - val_rmse: 0.1238\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0156 - rmse: 0.0156 - val_loss: 0.1242 - val_rmse: 0.1242\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0150 - rmse: 0.0150 - val_loss: 0.1242 - val_rmse: 0.1242\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.1242 - val_rmse: 0.1242\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0143 - rmse: 0.0143 - val_loss: 0.1242 - val_rmse: 0.1242\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0139 - rmse: 0.0139 - val_loss: 0.1238 - val_rmse: 0.1238\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0136 - rmse: 0.0136 - val_loss: 0.1239 - val_rmse: 0.1239\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0131 - rmse: 0.0131 - val_loss: 0.1240 - val_rmse: 0.1240\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1244 - val_rmse: 0.1244\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0127 - rmse: 0.0127 - val_loss: 0.1241 - val_rmse: 0.1241\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0124 - rmse: 0.0124 - val_loss: 0.1240 - val_rmse: 0.1240\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1237 - val_rmse: 0.1237\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1241 - val_rmse: 0.1241\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1241 - val_rmse: 0.1241\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1241 - val_rmse: 0.1241\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1239 - val_rmse: 0.1239\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1242 - val_rmse: 0.1242\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0110 - rmse: 0.0110 - val_loss: 0.1240 - val_rmse: 0.1240\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1240 - val_rmse: 0.1240\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1244 - val_rmse: 0.1244\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1242 - val_rmse: 0.1242\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1241 - val_rmse: 0.1241\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1244 - val_rmse: 0.1244\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1243 - val_rmse: 0.1243\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1245 - val_rmse: 0.1245\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1241 - val_rmse: 0.1241\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1250 - val_rmse: 0.1250\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1243 - val_rmse: 0.1243\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1243 - val_rmse: 0.1243\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1244 - val_rmse: 0.1244\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0089 - rmse: 0.0089 - val_loss: 0.1246 - val_rmse: 0.1246\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1248 - val_rmse: 0.1248\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1248 - val_rmse: 0.1248\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0085 - rmse: 0.0085 - val_loss: 0.1243 - val_rmse: 0.1243\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1248 - val_rmse: 0.1248\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0083 - rmse: 0.0083 - val_loss: 0.1247 - val_rmse: 0.1247\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1251 - val_rmse: 0.1251\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0084 - rmse: 0.0084 - val_loss: 0.1246 - val_rmse: 0.1246\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0082 - rmse: 0.0082 - val_loss: 0.1245 - val_rmse: 0.1245\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0080 - rmse: 0.0080 - val_loss: 0.1248 - val_rmse: 0.1248\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0081 - rmse: 0.0081 - val_loss: 0.1252 - val_rmse: 0.1252\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0080 - rmse: 0.0080 - val_loss: 0.1247 - val_rmse: 0.1247\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0079 - rmse: 0.0079 - val_loss: 0.1247 - val_rmse: 0.1247\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0079 - rmse: 0.0079 - val_loss: 0.1248 - val_rmse: 0.1248\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0077 - rmse: 0.0077 - val_loss: 0.1251 - val_rmse: 0.1251\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0078 - rmse: 0.0078 - val_loss: 0.1249 - val_rmse: 0.1249\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0076 - rmse: 0.0076 - val_loss: 0.1247 - val_rmse: 0.1247\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0076 - rmse: 0.0076 - val_loss: 0.1250 - val_rmse: 0.1250\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0075 - rmse: 0.0075 - val_loss: 0.1251 - val_rmse: 0.1251\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0072 - rmse: 0.0072 - val_loss: 0.1249 - val_rmse: 0.1249\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0077 - rmse: 0.0077 - val_loss: 0.1251 - val_rmse: 0.1251\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0076 - rmse: 0.0076 - val_loss: 0.1248 - val_rmse: 0.1248\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0072 - rmse: 0.0072Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0072 - rmse: 0.0072 - val_loss: 0.1250 - val_rmse: 0.1250\n",
            "Epoch 00067: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  16  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0319 - rmse: 0.0319 - val_loss: 0.1147 - val_rmse: 0.1147\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0202 - rmse: 0.0202 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0169 - rmse: 0.0169 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0149 - rmse: 0.0149 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0144 - rmse: 0.0144 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1131 - val_rmse: 0.1131\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1132 - val_rmse: 0.1132\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1132 - val_rmse: 0.1132\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1124 - val_rmse: 0.1124\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1132 - val_rmse: 0.1132\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1124 - val_rmse: 0.1124\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1136 - val_rmse: 0.1136\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0081 - rmse: 0.0081 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0079 - rmse: 0.0079 - val_loss: 0.1131 - val_rmse: 0.1131\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0075 - rmse: 0.0075 - val_loss: 0.1124 - val_rmse: 0.1124\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0075 - rmse: 0.0075 - val_loss: 0.1131 - val_rmse: 0.1131\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0074 - rmse: 0.0074 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0073 - rmse: 0.0073 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0072 - rmse: 0.0072 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0070 - rmse: 0.0070 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0069 - rmse: 0.0069 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0067 - rmse: 0.0067 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0071 - rmse: 0.0071 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0066 - rmse: 0.0066 - val_loss: 0.1123 - val_rmse: 0.1123\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0069 - rmse: 0.0069 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0065 - rmse: 0.0065 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0069 - rmse: 0.0069 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0065 - rmse: 0.0065 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0066 - rmse: 0.0066 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0067 - rmse: 0.0067 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0067 - rmse: 0.0067 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0065 - rmse: 0.0065 - val_loss: 0.1123 - val_rmse: 0.1123\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0065 - rmse: 0.0065 - val_loss: 0.1124 - val_rmse: 0.1124\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0060 - rmse: 0.0060 - val_loss: 0.1123 - val_rmse: 0.1123\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0061 - rmse: 0.0061 - val_loss: 0.1122 - val_rmse: 0.1122\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0063 - rmse: 0.0063 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0063 - rmse: 0.0063 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0064 - rmse: 0.0064 - val_loss: 0.1124 - val_rmse: 0.1124\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0058 - rmse: 0.0058 - val_loss: 0.1122 - val_rmse: 0.1122\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0061 - rmse: 0.0061 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0060 - rmse: 0.0060 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0059 - rmse: 0.0059 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0065 - rmse: 0.0065 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0060 - rmse: 0.0060 - val_loss: 0.1127 - val_rmse: 0.1127\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0062 - rmse: 0.0062 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0065 - rmse: 0.0065 - val_loss: 0.1122 - val_rmse: 0.1122\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0066 - rmse: 0.0066 - val_loss: 0.1117 - val_rmse: 0.1117\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0060 - rmse: 0.0060 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0059 - rmse: 0.0059 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0063 - rmse: 0.0063 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0059 - rmse: 0.0059 - val_loss: 0.1124 - val_rmse: 0.1124\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0056 - rmse: 0.0056 - val_loss: 0.1118 - val_rmse: 0.1118\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0058 - rmse: 0.0058 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0057 - rmse: 0.0057Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0057 - rmse: 0.0057 - val_loss: 0.1119 - val_rmse: 0.1119\n",
            "Epoch 00062: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  17  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0365 - rmse: 0.0365 - val_loss: 0.1247 - val_rmse: 0.1247\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0288 - rmse: 0.0288 - val_loss: 0.1250 - val_rmse: 0.1250\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0260 - rmse: 0.0260 - val_loss: 0.1247 - val_rmse: 0.1247\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0241 - rmse: 0.0241 - val_loss: 0.1249 - val_rmse: 0.1249\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0226 - rmse: 0.0226 - val_loss: 0.1251 - val_rmse: 0.1251\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0214 - rmse: 0.0214 - val_loss: 0.1259 - val_rmse: 0.1259\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0204 - rmse: 0.0204 - val_loss: 0.1255 - val_rmse: 0.1255\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0193 - rmse: 0.0193 - val_loss: 0.1260 - val_rmse: 0.1260\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0186 - rmse: 0.0186 - val_loss: 0.1272 - val_rmse: 0.1272\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0182 - rmse: 0.0182 - val_loss: 0.1268 - val_rmse: 0.1268\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0171 - rmse: 0.0171 - val_loss: 0.1273 - val_rmse: 0.1273\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0165 - rmse: 0.0165 - val_loss: 0.1274 - val_rmse: 0.1274\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0160 - rmse: 0.0160 - val_loss: 0.1284 - val_rmse: 0.1284\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0154 - rmse: 0.0154 - val_loss: 0.1282 - val_rmse: 0.1282\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0151 - rmse: 0.0151 - val_loss: 0.1281 - val_rmse: 0.1281\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.1278 - val_rmse: 0.1278\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0143 - rmse: 0.0143 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1277 - val_rmse: 0.1277\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0135 - rmse: 0.0135 - val_loss: 0.1291 - val_rmse: 0.1291\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1280 - val_rmse: 0.1280\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1287 - val_rmse: 0.1287\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1282 - val_rmse: 0.1282\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0127 - rmse: 0.0127 - val_loss: 0.1275 - val_rmse: 0.1275\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1289 - val_rmse: 0.1289\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1293 - val_rmse: 0.1293\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1285 - val_rmse: 0.1285\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1282 - val_rmse: 0.1282\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0116 - rmse: 0.0116 - val_loss: 0.1281 - val_rmse: 0.1281\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0116 - rmse: 0.0116 - val_loss: 0.1286 - val_rmse: 0.1286\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1283 - val_rmse: 0.1283\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0109 - rmse: 0.0109 - val_loss: 0.1293 - val_rmse: 0.1293\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1281 - val_rmse: 0.1281\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1283 - val_rmse: 0.1283\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1290 - val_rmse: 0.1290\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1284 - val_rmse: 0.1284\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1281 - val_rmse: 0.1281\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1281 - val_rmse: 0.1281\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1288 - val_rmse: 0.1288\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1262 - val_rmse: 0.1262\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1284 - val_rmse: 0.1284\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1287 - val_rmse: 0.1287\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1277 - val_rmse: 0.1277\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1283 - val_rmse: 0.1283\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1288 - val_rmse: 0.1288\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1272 - val_rmse: 0.1272\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1276 - val_rmse: 0.1276\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1271 - val_rmse: 0.1271\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1260 - val_rmse: 0.1260\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1268 - val_rmse: 0.1268\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1295 - val_rmse: 0.1295\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1266 - val_rmse: 0.1266\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1259 - val_rmse: 0.1259\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1272 - val_rmse: 0.1272\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1271 - val_rmse: 0.1271\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1247 - val_rmse: 0.1247\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0089 - rmse: 0.0089 - val_loss: 0.1258 - val_rmse: 0.1258\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1275 - val_rmse: 0.1275\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1278 - val_rmse: 0.1278\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1273 - val_rmse: 0.1273\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1263 - val_rmse: 0.1263\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.1261 - val_rmse: 0.1261\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0084 - rmse: 0.0084 - val_loss: 0.1266 - val_rmse: 0.1266\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0086 - rmse: 0.0086Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1269 - val_rmse: 0.1269\n",
            "Epoch 00063: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  18  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0411 - rmse: 0.0411 - val_loss: 0.1182 - val_rmse: 0.1182\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0241 - rmse: 0.0241 - val_loss: 0.1141 - val_rmse: 0.1141\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0196 - rmse: 0.0196 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0176 - rmse: 0.0176 - val_loss: 0.1116 - val_rmse: 0.1116\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0161 - rmse: 0.0161 - val_loss: 0.1113 - val_rmse: 0.1113\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0146 - rmse: 0.0146 - val_loss: 0.1112 - val_rmse: 0.1112\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1111 - val_rmse: 0.1111\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1106 - val_rmse: 0.1106\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1103 - val_rmse: 0.1103\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1103 - val_rmse: 0.1103\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0118 - rmse: 0.0118 - val_loss: 0.1097 - val_rmse: 0.1097\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1099 - val_rmse: 0.1099\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1088 - val_rmse: 0.1088\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0116 - rmse: 0.0116 - val_loss: 0.1102 - val_rmse: 0.1102\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1092 - val_rmse: 0.1092\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1096 - val_rmse: 0.1096\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1092 - val_rmse: 0.1092\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1085 - val_rmse: 0.1085\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1087 - val_rmse: 0.1087\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1082 - val_rmse: 0.1082\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0084 - rmse: 0.0084 - val_loss: 0.1083 - val_rmse: 0.1083\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1075 - val_rmse: 0.1075\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1088 - val_rmse: 0.1088\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0081 - rmse: 0.0081 - val_loss: 0.1077 - val_rmse: 0.1077\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0085 - rmse: 0.0085 - val_loss: 0.1086 - val_rmse: 0.1086\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1074 - val_rmse: 0.1074\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0082 - rmse: 0.0082 - val_loss: 0.1079 - val_rmse: 0.1079\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1080 - val_rmse: 0.1080\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1080 - val_rmse: 0.1080\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1072 - val_rmse: 0.1072\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0082 - rmse: 0.0082 - val_loss: 0.1074 - val_rmse: 0.1074\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1079 - val_rmse: 0.1079\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1076 - val_rmse: 0.1076\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0081 - rmse: 0.0081 - val_loss: 0.1077 - val_rmse: 0.1077\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0078 - rmse: 0.0078 - val_loss: 0.1082 - val_rmse: 0.1082\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0084 - rmse: 0.0084 - val_loss: 0.1077 - val_rmse: 0.1077\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1061 - val_rmse: 0.1061\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0086 - rmse: 0.0086 - val_loss: 0.1063 - val_rmse: 0.1063\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.1063 - val_rmse: 0.1063\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0085 - rmse: 0.0085 - val_loss: 0.1058 - val_rmse: 0.1058\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0079 - rmse: 0.0079 - val_loss: 0.1079 - val_rmse: 0.1079\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0080 - rmse: 0.0080 - val_loss: 0.1063 - val_rmse: 0.1063\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0085 - rmse: 0.0085 - val_loss: 0.1058 - val_rmse: 0.1058\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0084 - rmse: 0.0084 - val_loss: 0.1068 - val_rmse: 0.1068\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0079 - rmse: 0.0079 - val_loss: 0.1073 - val_rmse: 0.1073\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0076 - rmse: 0.0076 - val_loss: 0.1060 - val_rmse: 0.1060\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0081 - rmse: 0.0081 - val_loss: 0.1064 - val_rmse: 0.1064\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0079 - rmse: 0.0079 - val_loss: 0.1069 - val_rmse: 0.1069\n",
            "Epoch 57/200\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0083 - rmse: 0.0083Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0083 - rmse: 0.0083 - val_loss: 0.1070 - val_rmse: 0.1070\n",
            "Epoch 00057: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  19  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0416 - rmse: 0.0416 - val_loss: 0.1273 - val_rmse: 0.1273\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0299 - rmse: 0.0299 - val_loss: 0.1272 - val_rmse: 0.1272\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0375 - rmse: 0.0375 - val_loss: 0.1328 - val_rmse: 0.1328\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0596 - rmse: 0.0596 - val_loss: 0.1179 - val_rmse: 0.1179\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0384 - rmse: 0.0384 - val_loss: 0.1181 - val_rmse: 0.1181\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0295 - rmse: 0.0295 - val_loss: 0.1190 - val_rmse: 0.1190\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0256 - rmse: 0.0256 - val_loss: 0.1202 - val_rmse: 0.1202\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0234 - rmse: 0.0234 - val_loss: 0.1193 - val_rmse: 0.1193\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0222 - rmse: 0.0222 - val_loss: 0.1185 - val_rmse: 0.1185\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0206 - rmse: 0.0206 - val_loss: 0.1202 - val_rmse: 0.1202\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0195 - rmse: 0.0195 - val_loss: 0.1203 - val_rmse: 0.1203\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0186 - rmse: 0.0186 - val_loss: 0.1203 - val_rmse: 0.1203\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0185 - rmse: 0.0185 - val_loss: 0.1189 - val_rmse: 0.1189\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0174 - rmse: 0.0174 - val_loss: 0.1218 - val_rmse: 0.1218\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0169 - rmse: 0.0169 - val_loss: 0.1185 - val_rmse: 0.1185\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0162 - rmse: 0.0162 - val_loss: 0.1197 - val_rmse: 0.1197\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0162 - rmse: 0.0162 - val_loss: 0.1171 - val_rmse: 0.1171\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0155 - rmse: 0.0155 - val_loss: 0.1204 - val_rmse: 0.1204\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.1181 - val_rmse: 0.1181\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0144 - rmse: 0.0144 - val_loss: 0.1186 - val_rmse: 0.1186\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0146 - rmse: 0.0146 - val_loss: 0.1176 - val_rmse: 0.1176\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0149 - rmse: 0.0149 - val_loss: 0.1184 - val_rmse: 0.1184\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1173 - val_rmse: 0.1173\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0132 - rmse: 0.0132 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0139 - rmse: 0.0139 - val_loss: 0.1211 - val_rmse: 0.1211\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1193 - val_rmse: 0.1193\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0133 - rmse: 0.0133 - val_loss: 0.1176 - val_rmse: 0.1176\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0131 - rmse: 0.0131 - val_loss: 0.1178 - val_rmse: 0.1178\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0121 - rmse: 0.0121 - val_loss: 0.1163 - val_rmse: 0.1163\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0119 - rmse: 0.0119 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0129 - rmse: 0.0129 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0123 - rmse: 0.0123 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1174 - val_rmse: 0.1174\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1167 - val_rmse: 0.1167\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1178 - val_rmse: 0.1178\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1154 - val_rmse: 0.1154\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0116 - rmse: 0.0116 - val_loss: 0.1177 - val_rmse: 0.1177\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1178 - val_rmse: 0.1178\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0117 - rmse: 0.0117 - val_loss: 0.1168 - val_rmse: 0.1168\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1175 - val_rmse: 0.1175\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1149 - val_rmse: 0.1149\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1149 - val_rmse: 0.1149\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1167 - val_rmse: 0.1167\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0116 - rmse: 0.0116 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1147 - val_rmse: 0.1147\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1163 - val_rmse: 0.1163\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1152 - val_rmse: 0.1152\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 68/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1186 - val_rmse: 0.1186\n",
            "Epoch 69/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0159 - rmse: 0.0159 - val_loss: 0.1268 - val_rmse: 0.1268\n",
            "Epoch 70/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0139 - rmse: 0.0139 - val_loss: 0.1197 - val_rmse: 0.1197\n",
            "Epoch 71/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1200 - val_rmse: 0.1200\n",
            "Epoch 72/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1185 - val_rmse: 0.1185\n",
            "Epoch 73/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1193 - val_rmse: 0.1193\n",
            "Epoch 74/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1169 - val_rmse: 0.1169\n",
            "Epoch 75/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1188 - val_rmse: 0.1188\n",
            "Epoch 76/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1172 - val_rmse: 0.1172\n",
            "Epoch 77/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 78/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.1184 - val_rmse: 0.1184\n",
            "Epoch 79/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1187 - val_rmse: 0.1187\n",
            "Epoch 80/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 81/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1175 - val_rmse: 0.1175\n",
            "Epoch 82/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 83/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1156 - val_rmse: 0.1156\n",
            "Epoch 84/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1167 - val_rmse: 0.1167\n",
            "Epoch 85/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1164 - val_rmse: 0.1164\n",
            "Epoch 86/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.1175 - val_rmse: 0.1175\n",
            "Epoch 87/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1148 - val_rmse: 0.1148\n",
            "Epoch 88/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1190 - val_rmse: 0.1190\n",
            "Epoch 89/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1161 - val_rmse: 0.1161\n",
            "Epoch 90/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1163 - val_rmse: 0.1163\n",
            "Epoch 91/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0084 - rmse: 0.0084 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 92/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 93/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 94/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1139 - val_rmse: 0.1139\n",
            "Epoch 95/200\n",
            "40/40 [==============================] - 4s 94ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 96/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 97/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 98/200\n",
            "40/40 [==============================] - 4s 91ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.1157 - val_rmse: 0.1157\n",
            "Epoch 99/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0106 - rmse: 0.0106 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 100/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0088 - rmse: 0.0088 - val_loss: 0.1166 - val_rmse: 0.1166\n",
            "Epoch 101/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 102/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 103/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0083 - rmse: 0.0083 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 104/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0087 - rmse: 0.0087 - val_loss: 0.1179 - val_rmse: 0.1179\n",
            "Epoch 105/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0103 - rmse: 0.0103 - val_loss: 0.1162 - val_rmse: 0.1162\n",
            "Epoch 106/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 107/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0101 - rmse: 0.0101Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1159 - val_rmse: 0.1159\n",
            "Epoch 00107: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  20  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0382 - rmse: 0.0382 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0262 - rmse: 0.0262 - val_loss: 0.1139 - val_rmse: 0.1139\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0220 - rmse: 0.0220 - val_loss: 0.1158 - val_rmse: 0.1158\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0199 - rmse: 0.0199 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0179 - rmse: 0.0179 - val_loss: 0.1165 - val_rmse: 0.1165\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0171 - rmse: 0.0171 - val_loss: 0.1154 - val_rmse: 0.1154\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0163 - rmse: 0.0163 - val_loss: 0.1138 - val_rmse: 0.1138\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0147 - rmse: 0.0147 - val_loss: 0.1154 - val_rmse: 0.1154\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0141 - rmse: 0.0141 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1140 - val_rmse: 0.1140\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0131 - rmse: 0.0131 - val_loss: 0.1139 - val_rmse: 0.1139\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0127 - rmse: 0.0127 - val_loss: 0.1150 - val_rmse: 0.1150\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0130 - rmse: 0.0130 - val_loss: 0.1153 - val_rmse: 0.1153\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0122 - rmse: 0.0122 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0134 - rmse: 0.0134 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0126 - rmse: 0.0126 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1141 - val_rmse: 0.1141\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0108 - rmse: 0.0108 - val_loss: 0.1145 - val_rmse: 0.1145\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1142 - val_rmse: 0.1142\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.1160 - val_rmse: 0.1160\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0115 - rmse: 0.0115 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.1132 - val_rmse: 0.1132\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.1120 - val_rmse: 0.1120\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1137 - val_rmse: 0.1137\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1119 - val_rmse: 0.1119\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.1128 - val_rmse: 0.1128\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0105 - rmse: 0.0105 - val_loss: 0.1118 - val_rmse: 0.1118\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1123 - val_rmse: 0.1123\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0104 - rmse: 0.0104 - val_loss: 0.1117 - val_rmse: 0.1117\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1129 - val_rmse: 0.1129\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1116 - val_rmse: 0.1116\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1112 - val_rmse: 0.1112\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1119 - val_rmse: 0.1119\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1111 - val_rmse: 0.1111\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0085 - rmse: 0.0085 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0098 - rmse: 0.0098 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.1123 - val_rmse: 0.1123\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0096 - rmse: 0.0096 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1116 - val_rmse: 0.1116\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0214 - rmse: 0.0214 - val_loss: 0.1088 - val_rmse: 0.1088\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0173 - rmse: 0.0173 - val_loss: 0.1126 - val_rmse: 0.1126\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0135 - rmse: 0.0135 - val_loss: 0.1067 - val_rmse: 0.1067\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1067 - val_rmse: 0.1067\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0114 - rmse: 0.0114 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0111 - rmse: 0.0111 - val_loss: 0.1074 - val_rmse: 0.1074\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.1078 - val_rmse: 0.1078\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1073 - val_rmse: 0.1073\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.1081 - val_rmse: 0.1081\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.1087 - val_rmse: 0.1087\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1054 - val_rmse: 0.1054\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.1086 - val_rmse: 0.1086\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1085 - val_rmse: 0.1085\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0113 - rmse: 0.0113 - val_loss: 0.1056 - val_rmse: 0.1056\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.0101 - rmse: 0.0101Restoring model weights from the end of the best epoch.\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0101 - rmse: 0.0101 - val_loss: 0.1071 - val_rmse: 0.1071\n",
            "Epoch 00058: early stopping\n",
            "Saved model: LSTMonlineCudnnData\n",
            "\n",
            "Fitting series:  21  out of: 32\n",
            "Epoch 1/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0319 - rmse: 0.0319 - val_loss: 0.1134 - val_rmse: 0.1134\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0237 - rmse: 0.0237 - val_loss: 0.1114 - val_rmse: 0.1114\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0231 - rmse: 0.0231 - val_loss: 0.1130 - val_rmse: 0.1130\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0202 - rmse: 0.0202 - val_loss: 0.1100 - val_rmse: 0.1100\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0186 - rmse: 0.0186 - val_loss: 0.1121 - val_rmse: 0.1121\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0165 - rmse: 0.0165 - val_loss: 0.1122 - val_rmse: 0.1122\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0156 - rmse: 0.0156 - val_loss: 0.1115 - val_rmse: 0.1115\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0151 - rmse: 0.0151 - val_loss: 0.1078 - val_rmse: 0.1078\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0138 - rmse: 0.0138 - val_loss: 0.1113 - val_rmse: 0.1113\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0137 - rmse: 0.0137 - val_loss: 0.1122 - val_rmse: 0.1122\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 4s 93ms/step - loss: 0.0139 - rmse: 0.0139 - val_loss: 0.1125 - val_rmse: 0.1125\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 4s 92ms/step - loss: 0.0135 - rmse: 0.0135 - val_loss: 0.1097 - val_rmse: 0.1097\n",
            "Epoch 13/200\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0123 - rmse: 0.0123Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0GOG4F3Dpf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def forecast(machines, manual):\n",
        "        # Machines\n",
        "        machine_keys = list(machines.keys())\n",
        "        # Shortcuts\n",
        "        machine = machines[machine_keys[0]]\n",
        "        delta = machine.arch['delta']\n",
        "        n_pattern_steps = machine.arch['n_pattern_steps']\n",
        "        n_target_steps = machine.arch['n_target_steps']\n",
        "        # Series\n",
        "        key = 'batch'+str(manual['series_to_predict']%len(manual['stack'][machine.arch['preprocess_type']]))\n",
        "        n_steps = manual['stack'][machine.arch['preprocess_type']][key].n_steps\n",
        "        series = manual['stack'][machine.arch['preprocess_type']][key]\n",
        "        n_series = int((n_steps-n_pattern_steps)/n_target_steps)\n",
        "        # Initial\n",
        "        initial_indices = np.arange(0,delta*n_pattern_steps,delta)\n",
        "        patterns = {}\n",
        "        for i in range(len(machine.arch['pattern_sensors'])):\n",
        "            patterns.update({ \n",
        "            'accel_input_'+machine.arch['pattern_sensors'][i] : \n",
        "                np.reshape(\n",
        "                    series.data[machine.sensor_to_predict][initial_indices], \n",
        "                    [1,machine.arch['n_pattern_steps']]\n",
        "                )\n",
        "            })\n",
        "        forecasts = patterns.copy()\n",
        "        evaluation = {}\n",
        "        for i in range(n_series+1):\n",
        "            old_patterns = patterns.copy()\n",
        "            for j in range(len(machine_keys)):\n",
        "                machine = machines[machine_keys[j]] # Pick machine\n",
        "                prediction = machine.model.predict(\n",
        "                    old_patterns,\n",
        "                    batch_size = 1, \n",
        "                    verbose=0,\n",
        "                    steps = 1) # Make prediction with machine\n",
        "                pattern = patterns['accel_input_'+machine.arch['pattern_sensors'][j]] # Extract pattern\n",
        "                pattern = np.delete(pattern,np.s_[0:n_target_steps:delta],1) # Remove first entty\n",
        "                pattern = np.hstack([pattern,prediction]) # Add prediciton last\n",
        "                patterns.update({\n",
        "                    'accel_input_'+machine.arch['pattern_sensors'][j] : pattern\n",
        "                    }) # Update patterns dict\n",
        "                forecast = forecasts['accel_input_'+machine.arch['pattern_sensors'][j]] #Extract forecast\n",
        "                if i == n_series: # Edge case for last bit                   \n",
        "                    forecast = np.hstack(\n",
        "                        [forecast,\n",
        "                        prediction[:,:n_steps%(n_series*n_target_steps+n_pattern_steps)]]\n",
        "                        ) # Update forecast\n",
        "                else:\n",
        "                    forecast = np.hstack([forecast,prediction]) # Update forecast\n",
        "                forecasts.update({\n",
        "                    'accel_input_'+machine.arch['pattern_sensors'][j] : forecast\n",
        "                    }) # Update forecasts dict\n",
        "        score = rmse_np(\n",
        "            series.data[j][n_pattern_steps:], \n",
        "            forecasts['accel_input_'+machine.arch['pattern_sensors'][j]][0][n_pattern_steps:])\n",
        "        speed = series.speed['km/h']\n",
        "        damage_state = series.damage_state\n",
        "        return forecasts, (score, speed, damage_state)\n",
        "NeuralNet.forecast = forecast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSNH7TpTDpgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef48ZFmYDpgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    for i in range(len(architecture['target_sensors'])):\n",
        "        architecture['target_sensor'] = architecture['target_sensors'][i]\n",
        "        name = architecture['name']\n",
        "        try:\n",
        "            f = open('models/'+name+'.json')\n",
        "            machine_stack.update({\n",
        "                name : NeuralNet(architecture,\n",
        "                     name,\n",
        "                     existing_model = True)\n",
        "            })\n",
        "        except IOError:    \n",
        "            machine_stack.update({\n",
        "                name : NeuralNet(architecture,\n",
        "                     name,\n",
        "                     existing_model = False)\n",
        "            })\n",
        "            NeuralNet.train(machine_stack[name], series_stack)  \n",
        "            save_model(machine_stack[name].model, name)\n",
        "            plot_loss(machine_stack[name], name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEEYwoVGDpgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "def plot_performance(score_stack, a, pod): # pod = prediction or forecast\n",
        "    cmap = plt.cm.rainbow\n",
        "    norm = colors.Normalize(vmin=33,vmax=100)\n",
        "    percentage_keys = list(score_stack)\n",
        "    for i in range(len(percentage_keys)): # Iterates over percentages\n",
        "        for j in range(len(score_stack[percentage_keys[i]]['speeds'])):\n",
        "            plt.plot(score_stack[percentage_keys[i]]['speeds'][j], \n",
        "                     score_stack[percentage_keys[i]]['scores'][j], \n",
        "                     color=cmap(norm(score_stack[percentage_keys[i]]['damage_state'][j])), \n",
        "                     marker='o')\n",
        "    plt.xlabel('Speed [km/h]')\n",
        "    plt.ylabel('Root Mean Square Error')\n",
        "    plt.title('Sample scores for '+pod+' at sensor ' + str(a['target_sensor']))\n",
        "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "    cbar = plt.colorbar(sm)\n",
        "    cbar.set_label('Young\\'s modulus percentage', rotation=270)\n",
        "    plt.legend()\n",
        "    plt.savefig(fname = a['name']+pod+'_performance_plot.png')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjiis5gGDzbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_performance(score_stack, architecture, 'prediction')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1nldO5ZE0kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmse_np(true, prediction):\n",
        "    return np.sqrt(np.mean(np.square(prediction - true), axis=-1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7BOT-ioFHSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_forecast(forecast, manual, a):\n",
        "    key = 'batch'+str(manual['series_to_predict'])\n",
        "    forecast_keys = list(forecast.keys())\n",
        "    for i in range(len(forecast_keys)): \n",
        "        plt.subplot(len(forecast_keys),1,i+1)\n",
        "        plt.plot(\n",
        "            manual['stack'][a['preprocess_type']][key].timesteps, \n",
        "            forecast[forecast_keys[i]][0], \n",
        "            'b', \n",
        "            linewidth=0.4)\n",
        "        plt.plot(\n",
        "            manual['stack'][a['preprocess_type']][key].timesteps, \n",
        "            manual['stack'][a['preprocess_type']][key].data[i], \n",
        "            'r', \n",
        "            linewidth=0.4)\n",
        "        plt.xlabel('timesteps')\n",
        "        plt.ylabel('accelerations')\n",
        "        #plt.title('Forecast for response at '+str(manual['stack'][a['preprocess_type']][key].speed['km/h']+' km/h'))\n",
        "        plt.legend(['Forecast', 'Signals']) \n",
        "    plt.savefig(fname = a['name']+'series'+str(manual['series_to_predict'])+'_forecast_plot.png')\n",
        "    plt.show() \n",
        "plot_forecast(forecast, prediction_manual, architecture)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JjShCT-ENA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    prediction_score = {}\n",
        "    for i in range(len(keys)):\n",
        "        #print(series_stack[keys[i]])\n",
        "        scores = []\n",
        "        speeds = []\n",
        "        damage_states = []\n",
        "        for j in range(len(series_stack[keys[i]][architecture['preprocess_type']])):\n",
        "            if series_stack[keys[i]][architecture['preprocess_type']]['batch'+str(j)].category == 'test':\n",
        "                prediction_manual = {\n",
        "                    'series_to_predict' : j,\n",
        "                    'stack' : series_stack[keys[i]]\n",
        "                }\n",
        "                #prediction = NeuralNet.prediction(machine_stack[name], prediction_manual)\n",
        "                #plot_prediction(prediction, prediction_manual, use)\n",
        "                forecast, tup = NeuralNet.forecast(machine_stack, prediction_manual)\n",
        "                scores.extend([tup[0]])\n",
        "                speeds.extend([tup[1]])\n",
        "                damage_states.extend([tup[2]])\n",
        "            else:\n",
        "                continue\n",
        "        prediction_score.update({\n",
        "            keys[i] : {'scores' : scores, 'speeds' : speeds, 'damage_state' : damage_states}           \n",
        "            })\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}